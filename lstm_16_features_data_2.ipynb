{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "lstm-16-features-data-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install xlrd==1.2.0 ### ######"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-04-26T14:55:11.200645Z",
          "iopub.execute_input": "2022-04-26T14:55:11.201212Z",
          "iopub.status.idle": "2022-04-26T14:55:18.892204Z",
          "shell.execute_reply.started": "2022-04-26T14:55:11.201172Z",
          "shell.execute_reply": "2022-04-26T14:55:18.891300Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHnHUYsuIIe",
        "outputId": "9256a85e-4e50-4f07-bbb8-b0c95d93efb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xlsxwriter"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:55:18.894823Z",
          "iopub.execute_input": "2022-04-26T14:55:18.895114Z",
          "iopub.status.idle": "2022-04-26T14:55:26.218908Z",
          "shell.execute_reply.started": "2022-04-26T14:55:18.895078Z",
          "shell.execute_reply": "2022-04-26T14:55:26.218035Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uetx79o9uIIk",
        "outputId": "96952077-1aec-4940-c5ea-f5438257a542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_file = \"LSTM_dataset_2\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:55:26.223115Z",
          "iopub.execute_input": "2022-04-26T14:55:26.223411Z",
          "iopub.status.idle": "2022-04-26T14:55:26.230366Z",
          "shell.execute_reply.started": "2022-04-26T14:55:26.223375Z",
          "shell.execute_reply": "2022-04-26T14:55:26.229688Z"
        },
        "trusted": true,
        "id": "aTZ_O9XfuIIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics , cross_decomposition, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.signal import savgol_filter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xlrd\n",
        "import xlsxwriter\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler #for calculate SNV\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler ## for calculate SNV\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut \n",
        "from sys import stdout\n",
        "import re\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from sklearn.model_selection import train_test_split   \n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.layers import Input\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ write name of output file name \n",
        "time1=time.time()\n",
        "\n",
        "# ================= import data\n",
        "workbook = xlrd.open_workbook(\"/IG-Dataset18_11.xlsx\",\"rb\")\n",
        "sheets = workbook.sheet_names()\n",
        "sheet_num=1  ## add sheet number # 5\n",
        "sh = workbook.sheet_by_name(sheets[(sheet_num)-1])\n",
        "n_cols=0 ##number of colum you have to delet from the front\n",
        "n_rows=0 ##number of rows you have to delet from the front \n",
        "m_cols=0 ## number of colum you have to delet from the end\n",
        "m_rows=0 ## number of rows you have to delet from the end\n",
        "M_rows=sh.nrows-m_rows\n",
        "M_cols=sh.ncols-m_cols\n",
        "required_data = []\n",
        "for rownum in range(n_rows,M_rows):\n",
        "    row_valaues = sh.row_values(rownum)\n",
        "    required_data.append(row_valaues[n_cols:M_cols])\n",
        "Required_data=np.asarray(required_data)\n",
        "X=Required_data[1:257674,0:16].astype(float)  #  25194 # 82334  ( 4:41 & 1:40)\n",
        "X= np.array (X)\n",
        "\n",
        "Y=Required_data[1:257674,17:18].astype(float).ravel()    # (42:43  & 41:42)\n",
        "print(X.shape)\n",
        "\n",
        "bands = Required_data[0:1, 0:16]      # ( 4:41 & 1:40)\n",
        "bands= np.array (bands)\n",
        "#===============\n",
        "X_train, X_test, y_train, y_test = split(X, Y, test_size=(0.20), random_state=0)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "# ==============================================\n",
        "\n",
        "nb_classes = len (np.unique( y_train ))\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 16, 1)   #Reshape for lstm - should work!!\n",
        "X_test= X_test.reshape(X_test.shape[0], 16, 1)\n",
        "\n",
        "print('class', nb_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:55:26.234190Z",
          "iopub.execute_input": "2022-04-26T14:55:26.235537Z",
          "iopub.status.idle": "2022-04-26T14:56:17.214159Z",
          "shell.execute_reply.started": "2022-04-26T14:55:26.235501Z",
          "shell.execute_reply": "2022-04-26T14:56:17.213392Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3o8FPKduIIn",
        "outputId": "3ddf420a-6968-432f-80f5-14bbb5f74583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(257673, 16)\n",
            "class 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, Flatten, MaxPooling2D,BatchNormalization\n",
        "from keras.layers import LSTM,TimeDistributed,Conv1D,MaxPooling1D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "model_lstm = Sequential() #=============================== climate-based model\n",
        "model_lstm.add(LSTM(units = 512, return_sequences = True, input_shape = (16,1), activation='tanh'))\n",
        "model_lstm.add(LSTM(units = 256, return_sequences = True))\n",
        "model_lstm.add(Dense(128, activation='relu'))\n",
        "model_lstm.add(Dense(64, activation='relu'))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(32, activation='relu'))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Flatten())\n",
        "model_lstm.add(Dense(nb_classes, activation='softmax'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:17.215318Z",
          "iopub.execute_input": "2022-04-26T14:56:17.215912Z",
          "iopub.status.idle": "2022-04-26T14:56:17.844822Z",
          "shell.execute_reply.started": "2022-04-26T14:56:17.215873Z",
          "shell.execute_reply": "2022-04-26T14:56:17.844098Z"
        },
        "trusted": true,
        "id": "3oXJ3YpWuIIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model_lstm, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:17.846129Z",
          "iopub.execute_input": "2022-04-26T14:56:17.846369Z",
          "iopub.status.idle": "2022-04-26T14:56:18.040096Z",
          "shell.execute_reply.started": "2022-04-26T14:56:17.846327Z",
          "shell.execute_reply": "2022-04-26T14:56:18.039354Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u_jPdNwluIIq",
        "outputId": "bcfc8e22-19b6-4c70-d671-d6f171e619af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "model_lstm.compile(loss=keras.losses.binary_crossentropy,optimizer='RMSprop',metrics=['accuracy'])  \n",
        "\n",
        "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
        "mc = ModelCheckpoint(name_file +'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "cnn11 = model_lstm.fit(X_train,Y_train, batch_size=300, epochs=500, validation_data=(X_test ,Y_test), callbacks=[mc,csv_logger])\n",
        "print ((\"Training time=\", time.time()-time1))\n",
        "np.save(\"LSTM_data_2_@history\", cnn11.history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:18.042011Z",
          "iopub.execute_input": "2022-04-26T14:56:18.042477Z",
          "iopub.status.idle": "2022-04-26T14:56:44.896210Z",
          "shell.execute_reply.started": "2022-04-26T14:56:18.042441Z",
          "shell.execute_reply": "2022-04-26T14:56:44.894419Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWIoffeEuIIr",
        "outputId": "826453f4-9725-4e1e-a0da-468184c6efe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.7982\n",
            "Epoch 1: val_loss improved from inf to 0.32216, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 22s 21ms/step - loss: 0.4196 - accuracy: 0.7982 - val_loss: 0.3222 - val_accuracy: 0.8600\n",
            "Epoch 2/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8596\n",
            "Epoch 2: val_loss did not improve from 0.32216\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.2996 - accuracy: 0.8597 - val_loss: 0.3318 - val_accuracy: 0.8567\n",
            "Epoch 3/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.8786\n",
            "Epoch 3: val_loss improved from 0.32216 to 0.28515, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2537 - accuracy: 0.8787 - val_loss: 0.2851 - val_accuracy: 0.8633\n",
            "Epoch 4/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.8880\n",
            "Epoch 4: val_loss improved from 0.28515 to 0.21237, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2300 - accuracy: 0.8880 - val_loss: 0.2124 - val_accuracy: 0.8937\n",
            "Epoch 5/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.8946\n",
            "Epoch 5: val_loss did not improve from 0.21237\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.2127 - accuracy: 0.8946 - val_loss: 0.2783 - val_accuracy: 0.8776\n",
            "Epoch 6/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.8967\n",
            "Epoch 6: val_loss improved from 0.21237 to 0.20194, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2037 - accuracy: 0.8967 - val_loss: 0.2019 - val_accuracy: 0.8913\n",
            "Epoch 7/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9000\n",
            "Epoch 7: val_loss did not improve from 0.20194\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 0.2271 - val_accuracy: 0.8911\n",
            "Epoch 8/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.9031\n",
            "Epoch 8: val_loss did not improve from 0.20194\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1905 - accuracy: 0.9031 - val_loss: 0.7968 - val_accuracy: 0.8672\n",
            "Epoch 9/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.9049\n",
            "Epoch 9: val_loss did not improve from 0.20194\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1871 - accuracy: 0.9049 - val_loss: 0.2252 - val_accuracy: 0.8896\n",
            "Epoch 10/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1821 - accuracy: 0.9068\n",
            "Epoch 10: val_loss improved from 0.20194 to 0.19588, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1822 - accuracy: 0.9067 - val_loss: 0.1959 - val_accuracy: 0.8979\n",
            "Epoch 11/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9084\n",
            "Epoch 11: val_loss improved from 0.19588 to 0.17472, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1793 - accuracy: 0.9084 - val_loss: 0.1747 - val_accuracy: 0.9048\n",
            "Epoch 12/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9102\n",
            "Epoch 12: val_loss improved from 0.17472 to 0.17093, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1752 - accuracy: 0.9102 - val_loss: 0.1709 - val_accuracy: 0.9151\n",
            "Epoch 13/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9111\n",
            "Epoch 13: val_loss did not improve from 0.17093\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1740 - accuracy: 0.9112 - val_loss: 0.1764 - val_accuracy: 0.9094\n",
            "Epoch 14/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1706 - accuracy: 0.9131\n",
            "Epoch 14: val_loss improved from 0.17093 to 0.16927, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1706 - accuracy: 0.9131 - val_loss: 0.1693 - val_accuracy: 0.9120\n",
            "Epoch 15/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1706 - accuracy: 0.9128\n",
            "Epoch 15: val_loss did not improve from 0.16927\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1705 - accuracy: 0.9128 - val_loss: 0.1705 - val_accuracy: 0.9111\n",
            "Epoch 16/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9151\n",
            "Epoch 16: val_loss improved from 0.16927 to 0.15695, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1661 - accuracy: 0.9151 - val_loss: 0.1570 - val_accuracy: 0.9206\n",
            "Epoch 17/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9159\n",
            "Epoch 17: val_loss did not improve from 0.15695\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1646 - accuracy: 0.9159 - val_loss: 0.1688 - val_accuracy: 0.9133\n",
            "Epoch 18/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9165\n",
            "Epoch 18: val_loss did not improve from 0.15695\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1632 - accuracy: 0.9165 - val_loss: 0.1912 - val_accuracy: 0.8881\n",
            "Epoch 19/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9175\n",
            "Epoch 19: val_loss improved from 0.15695 to 0.14266, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1620 - accuracy: 0.9175 - val_loss: 0.1427 - val_accuracy: 0.9261\n",
            "Epoch 20/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9215\n",
            "Epoch 20: val_loss did not improve from 0.14266\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1562 - accuracy: 0.9215 - val_loss: 0.8495 - val_accuracy: 0.7811\n",
            "Epoch 21/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9240\n",
            "Epoch 21: val_loss did not improve from 0.14266\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1531 - accuracy: 0.9239 - val_loss: 0.1896 - val_accuracy: 0.9182\n",
            "Epoch 22/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9261\n",
            "Epoch 22: val_loss did not improve from 0.14266\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1496 - accuracy: 0.9261 - val_loss: 0.1992 - val_accuracy: 0.9243\n",
            "Epoch 23/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9276\n",
            "Epoch 23: val_loss did not improve from 0.14266\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1465 - accuracy: 0.9275 - val_loss: 0.1809 - val_accuracy: 0.9113\n",
            "Epoch 24/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9274\n",
            "Epoch 24: val_loss improved from 0.14266 to 0.13687, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1480 - accuracy: 0.9274 - val_loss: 0.1369 - val_accuracy: 0.9318\n",
            "Epoch 25/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9286\n",
            "Epoch 25: val_loss did not improve from 0.13687\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1456 - accuracy: 0.9286 - val_loss: 1.2326 - val_accuracy: 0.7910\n",
            "Epoch 26/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 0.9290\n",
            "Epoch 26: val_loss did not improve from 0.13687\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1477 - accuracy: 0.9290 - val_loss: 0.1544 - val_accuracy: 0.9290\n",
            "Epoch 27/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9291\n",
            "Epoch 27: val_loss did not improve from 0.13687\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1458 - accuracy: 0.9291 - val_loss: 0.1395 - val_accuracy: 0.9300\n",
            "Epoch 28/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9288\n",
            "Epoch 28: val_loss did not improve from 0.13687\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1448 - accuracy: 0.9288 - val_loss: 0.1517 - val_accuracy: 0.9245\n",
            "Epoch 29/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9298\n",
            "Epoch 29: val_loss did not improve from 0.13687\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1425 - accuracy: 0.9299 - val_loss: 0.1444 - val_accuracy: 0.9299\n",
            "Epoch 30/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1490 - accuracy: 0.9305\n",
            "Epoch 30: val_loss improved from 0.13687 to 0.13366, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1490 - accuracy: 0.9305 - val_loss: 0.1337 - val_accuracy: 0.9336\n",
            "Epoch 31/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9299\n",
            "Epoch 31: val_loss did not improve from 0.13366\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1411 - accuracy: 0.9299 - val_loss: 0.1382 - val_accuracy: 0.9308\n",
            "Epoch 32/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9300\n",
            "Epoch 32: val_loss did not improve from 0.13366\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1451 - accuracy: 0.9300 - val_loss: 0.1473 - val_accuracy: 0.9262\n",
            "Epoch 33/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9302\n",
            "Epoch 33: val_loss improved from 0.13366 to 0.13322, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1426 - accuracy: 0.9302 - val_loss: 0.1332 - val_accuracy: 0.9339\n",
            "Epoch 34/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9313\n",
            "Epoch 34: val_loss did not improve from 0.13322\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1440 - accuracy: 0.9313 - val_loss: 0.2207 - val_accuracy: 0.9030\n",
            "Epoch 35/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9314\n",
            "Epoch 35: val_loss did not improve from 0.13322\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1410 - accuracy: 0.9315 - val_loss: 0.1428 - val_accuracy: 0.9296\n",
            "Epoch 36/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9313\n",
            "Epoch 36: val_loss did not improve from 0.13322\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1417 - accuracy: 0.9313 - val_loss: 0.1404 - val_accuracy: 0.9308\n",
            "Epoch 37/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9314\n",
            "Epoch 37: val_loss did not improve from 0.13322\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1462 - accuracy: 0.9314 - val_loss: 0.1466 - val_accuracy: 0.9294\n",
            "Epoch 38/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9307\n",
            "Epoch 38: val_loss did not improve from 0.13322\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1441 - accuracy: 0.9307 - val_loss: 0.1481 - val_accuracy: 0.9320\n",
            "Epoch 39/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9309\n",
            "Epoch 39: val_loss improved from 0.13322 to 0.13172, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1449 - accuracy: 0.9309 - val_loss: 0.1317 - val_accuracy: 0.9355\n",
            "Epoch 40/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9313\n",
            "Epoch 40: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1465 - accuracy: 0.9313 - val_loss: 0.1378 - val_accuracy: 0.9330\n",
            "Epoch 41/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9309\n",
            "Epoch 41: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1455 - accuracy: 0.9306 - val_loss: 0.1795 - val_accuracy: 0.9180\n",
            "Epoch 42/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9309\n",
            "Epoch 42: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1440 - accuracy: 0.9309 - val_loss: 0.1663 - val_accuracy: 0.9282\n",
            "Epoch 43/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.9306\n",
            "Epoch 43: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1455 - accuracy: 0.9306 - val_loss: 0.1415 - val_accuracy: 0.9294\n",
            "Epoch 44/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9305\n",
            "Epoch 44: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1451 - accuracy: 0.9305 - val_loss: 0.1462 - val_accuracy: 0.9289\n",
            "Epoch 45/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9301\n",
            "Epoch 45: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1562 - accuracy: 0.9301 - val_loss: 0.1427 - val_accuracy: 0.9338\n",
            "Epoch 46/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9310\n",
            "Epoch 46: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1469 - accuracy: 0.9310 - val_loss: 0.1899 - val_accuracy: 0.9268\n",
            "Epoch 47/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9300\n",
            "Epoch 47: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1513 - accuracy: 0.9300 - val_loss: 0.1426 - val_accuracy: 0.9297\n",
            "Epoch 48/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9314\n",
            "Epoch 48: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1450 - accuracy: 0.9314 - val_loss: 0.1406 - val_accuracy: 0.9322\n",
            "Epoch 49/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9300\n",
            "Epoch 49: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1539 - accuracy: 0.9300 - val_loss: 0.1480 - val_accuracy: 0.9306\n",
            "Epoch 50/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9306\n",
            "Epoch 50: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1607 - accuracy: 0.9306 - val_loss: 0.1405 - val_accuracy: 0.9329\n",
            "Epoch 51/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9317\n",
            "Epoch 51: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1441 - accuracy: 0.9317 - val_loss: 0.1712 - val_accuracy: 0.9219\n",
            "Epoch 52/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9317\n",
            "Epoch 52: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1434 - accuracy: 0.9317 - val_loss: 0.1373 - val_accuracy: 0.9316\n",
            "Epoch 53/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9317\n",
            "Epoch 53: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1475 - accuracy: 0.9316 - val_loss: 0.1557 - val_accuracy: 0.9328\n",
            "Epoch 54/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9320\n",
            "Epoch 54: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1440 - accuracy: 0.9320 - val_loss: 0.1494 - val_accuracy: 0.9296\n",
            "Epoch 55/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 0.9312\n",
            "Epoch 55: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1428 - accuracy: 0.9312 - val_loss: 0.1356 - val_accuracy: 0.9333\n",
            "Epoch 56/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9314\n",
            "Epoch 56: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1510 - accuracy: 0.9315 - val_loss: 0.1494 - val_accuracy: 0.9268\n",
            "Epoch 57/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9307\n",
            "Epoch 57: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1449 - accuracy: 0.9308 - val_loss: 0.1433 - val_accuracy: 0.9320\n",
            "Epoch 58/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9313\n",
            "Epoch 58: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1452 - accuracy: 0.9313 - val_loss: 0.1400 - val_accuracy: 0.9339\n",
            "Epoch 59/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9318\n",
            "Epoch 59: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1454 - accuracy: 0.9318 - val_loss: 0.1399 - val_accuracy: 0.9309\n",
            "Epoch 60/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9316\n",
            "Epoch 60: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1447 - accuracy: 0.9316 - val_loss: 0.1437 - val_accuracy: 0.9304\n",
            "Epoch 61/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9316\n",
            "Epoch 61: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1465 - accuracy: 0.9316 - val_loss: 0.1512 - val_accuracy: 0.9299\n",
            "Epoch 62/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9321\n",
            "Epoch 62: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1539 - accuracy: 0.9320 - val_loss: 0.1460 - val_accuracy: 0.9320\n",
            "Epoch 63/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9317\n",
            "Epoch 63: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1478 - accuracy: 0.9317 - val_loss: 0.1359 - val_accuracy: 0.9339\n",
            "Epoch 64/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9325\n",
            "Epoch 64: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1437 - accuracy: 0.9324 - val_loss: 0.1470 - val_accuracy: 0.9247\n",
            "Epoch 65/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9315\n",
            "Epoch 65: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1530 - accuracy: 0.9315 - val_loss: 0.1706 - val_accuracy: 0.9304\n",
            "Epoch 66/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9320\n",
            "Epoch 66: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1483 - accuracy: 0.9320 - val_loss: 0.1733 - val_accuracy: 0.9188\n",
            "Epoch 67/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9315\n",
            "Epoch 67: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1518 - accuracy: 0.9315 - val_loss: 0.1382 - val_accuracy: 0.9348\n",
            "Epoch 68/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9325\n",
            "Epoch 68: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1452 - accuracy: 0.9325 - val_loss: 0.1781 - val_accuracy: 0.9334\n",
            "Epoch 69/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9325\n",
            "Epoch 69: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1457 - accuracy: 0.9325 - val_loss: 0.1369 - val_accuracy: 0.9342\n",
            "Epoch 70/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9315\n",
            "Epoch 70: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1941 - accuracy: 0.9315 - val_loss: 0.1461 - val_accuracy: 0.9235\n",
            "Epoch 71/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9328\n",
            "Epoch 71: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1456 - accuracy: 0.9328 - val_loss: 0.1630 - val_accuracy: 0.9286\n",
            "Epoch 72/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9330\n",
            "Epoch 72: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1478 - accuracy: 0.9329 - val_loss: 0.1465 - val_accuracy: 0.9309\n",
            "Epoch 73/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9325\n",
            "Epoch 73: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1483 - accuracy: 0.9324 - val_loss: 0.1395 - val_accuracy: 0.9328\n",
            "Epoch 74/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9314\n",
            "Epoch 74: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1467 - accuracy: 0.9314 - val_loss: 0.1517 - val_accuracy: 0.9282\n",
            "Epoch 75/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9324\n",
            "Epoch 75: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1650 - accuracy: 0.9324 - val_loss: 0.1596 - val_accuracy: 0.9350\n",
            "Epoch 76/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9326\n",
            "Epoch 76: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1526 - accuracy: 0.9325 - val_loss: 0.1530 - val_accuracy: 0.9290\n",
            "Epoch 77/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9323\n",
            "Epoch 77: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1516 - accuracy: 0.9323 - val_loss: 0.1379 - val_accuracy: 0.9346\n",
            "Epoch 78/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9332\n",
            "Epoch 78: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1457 - accuracy: 0.9333 - val_loss: 0.1553 - val_accuracy: 0.9326\n",
            "Epoch 79/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9319\n",
            "Epoch 79: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1483 - accuracy: 0.9319 - val_loss: 0.1602 - val_accuracy: 0.9323\n",
            "Epoch 80/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9317\n",
            "Epoch 80: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1520 - accuracy: 0.9317 - val_loss: 0.1354 - val_accuracy: 0.9363\n",
            "Epoch 81/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 0.9319\n",
            "Epoch 81: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1477 - accuracy: 0.9319 - val_loss: 0.2175 - val_accuracy: 0.9254\n",
            "Epoch 82/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9325\n",
            "Epoch 82: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1501 - accuracy: 0.9325 - val_loss: 0.3278 - val_accuracy: 0.9227\n",
            "Epoch 83/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9332\n",
            "Epoch 83: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1456 - accuracy: 0.9332 - val_loss: 0.1629 - val_accuracy: 0.9309\n",
            "Epoch 84/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9318\n",
            "Epoch 84: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1482 - accuracy: 0.9318 - val_loss: 0.1533 - val_accuracy: 0.9251\n",
            "Epoch 85/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9323\n",
            "Epoch 85: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1513 - accuracy: 0.9323 - val_loss: 0.1403 - val_accuracy: 0.9342\n",
            "Epoch 86/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9304\n",
            "Epoch 86: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1572 - accuracy: 0.9304 - val_loss: 0.1873 - val_accuracy: 0.9221\n",
            "Epoch 87/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9324\n",
            "Epoch 87: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1490 - accuracy: 0.9325 - val_loss: 0.1358 - val_accuracy: 0.9348\n",
            "Epoch 88/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9329\n",
            "Epoch 88: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1565 - accuracy: 0.9329 - val_loss: 0.1691 - val_accuracy: 0.9321\n",
            "Epoch 89/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9319\n",
            "Epoch 89: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1479 - accuracy: 0.9319 - val_loss: 0.1417 - val_accuracy: 0.9306\n",
            "Epoch 90/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9321\n",
            "Epoch 90: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1496 - accuracy: 0.9321 - val_loss: 0.1452 - val_accuracy: 0.9116\n",
            "Epoch 91/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9327\n",
            "Epoch 91: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1574 - accuracy: 0.9327 - val_loss: 0.1430 - val_accuracy: 0.9336\n",
            "Epoch 92/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9322\n",
            "Epoch 92: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1460 - accuracy: 0.9321 - val_loss: 0.2869 - val_accuracy: 0.9003\n",
            "Epoch 93/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9306\n",
            "Epoch 93: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1955 - accuracy: 0.9306 - val_loss: 0.1359 - val_accuracy: 0.9344\n",
            "Epoch 94/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9316\n",
            "Epoch 94: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2046 - accuracy: 0.9316 - val_loss: 0.1378 - val_accuracy: 0.9344\n",
            "Epoch 95/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9326\n",
            "Epoch 95: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1508 - accuracy: 0.9326 - val_loss: 0.1375 - val_accuracy: 0.9318\n",
            "Epoch 96/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9316\n",
            "Epoch 96: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1741 - accuracy: 0.9316 - val_loss: 0.1738 - val_accuracy: 0.9199\n",
            "Epoch 97/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9310\n",
            "Epoch 97: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1595 - accuracy: 0.9310 - val_loss: 0.1693 - val_accuracy: 0.9335\n",
            "Epoch 98/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9324\n",
            "Epoch 98: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1470 - accuracy: 0.9324 - val_loss: 0.1400 - val_accuracy: 0.9344\n",
            "Epoch 99/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9312\n",
            "Epoch 99: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1587 - accuracy: 0.9311 - val_loss: 0.1555 - val_accuracy: 0.9322\n",
            "Epoch 100/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.9327\n",
            "Epoch 100: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1692 - accuracy: 0.9327 - val_loss: 0.1534 - val_accuracy: 0.9296\n",
            "Epoch 101/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9325\n",
            "Epoch 101: val_loss did not improve from 0.13172\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1473 - accuracy: 0.9325 - val_loss: 0.1411 - val_accuracy: 0.9368\n",
            "Epoch 102/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9322\n",
            "Epoch 102: val_loss improved from 0.13172 to 0.12873, saving model to LSTM_dataset_2.h5\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1549 - accuracy: 0.9322 - val_loss: 0.1287 - val_accuracy: 0.9381\n",
            "Epoch 103/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9326\n",
            "Epoch 103: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1453 - accuracy: 0.9326 - val_loss: 0.1372 - val_accuracy: 0.9362\n",
            "Epoch 104/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9310\n",
            "Epoch 104: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1574 - accuracy: 0.9310 - val_loss: 0.1409 - val_accuracy: 0.9333\n",
            "Epoch 105/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9309\n",
            "Epoch 105: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1800 - accuracy: 0.9309 - val_loss: 0.1375 - val_accuracy: 0.9328\n",
            "Epoch 106/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9330\n",
            "Epoch 106: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1548 - accuracy: 0.9330 - val_loss: 0.1506 - val_accuracy: 0.9323\n",
            "Epoch 107/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.9329\n",
            "Epoch 107: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3049 - accuracy: 0.9329 - val_loss: 0.1410 - val_accuracy: 0.9340\n",
            "Epoch 108/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9327\n",
            "Epoch 108: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1445 - accuracy: 0.9327 - val_loss: 0.1517 - val_accuracy: 0.9319\n",
            "Epoch 109/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9328\n",
            "Epoch 109: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1476 - accuracy: 0.9327 - val_loss: 0.1439 - val_accuracy: 0.9290\n",
            "Epoch 110/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9317\n",
            "Epoch 110: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1505 - accuracy: 0.9317 - val_loss: 0.1430 - val_accuracy: 0.9332\n",
            "Epoch 111/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9321\n",
            "Epoch 111: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1545 - accuracy: 0.9321 - val_loss: 0.1507 - val_accuracy: 0.9191\n",
            "Epoch 112/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 0.9331\n",
            "Epoch 112: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1429 - accuracy: 0.9331 - val_loss: 0.1430 - val_accuracy: 0.9311\n",
            "Epoch 113/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9337\n",
            "Epoch 113: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1485 - accuracy: 0.9337 - val_loss: 0.1426 - val_accuracy: 0.9329\n",
            "Epoch 114/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9329\n",
            "Epoch 114: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1546 - accuracy: 0.9329 - val_loss: 0.1508 - val_accuracy: 0.9330\n",
            "Epoch 115/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9340\n",
            "Epoch 115: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1481 - accuracy: 0.9340 - val_loss: 0.1322 - val_accuracy: 0.9370\n",
            "Epoch 116/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9330\n",
            "Epoch 116: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1666 - accuracy: 0.9330 - val_loss: 0.1415 - val_accuracy: 0.9323\n",
            "Epoch 117/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9330\n",
            "Epoch 117: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1469 - accuracy: 0.9330 - val_loss: 0.1370 - val_accuracy: 0.9342\n",
            "Epoch 118/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9337\n",
            "Epoch 118: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1604 - accuracy: 0.9337 - val_loss: 0.1483 - val_accuracy: 0.9307\n",
            "Epoch 119/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 0.9330\n",
            "Epoch 119: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1534 - accuracy: 0.9330 - val_loss: 0.1544 - val_accuracy: 0.9260\n",
            "Epoch 120/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9326\n",
            "Epoch 120: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1655 - accuracy: 0.9326 - val_loss: 0.1463 - val_accuracy: 0.9352\n",
            "Epoch 121/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9334\n",
            "Epoch 121: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1454 - accuracy: 0.9333 - val_loss: 0.1353 - val_accuracy: 0.9343\n",
            "Epoch 122/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9330\n",
            "Epoch 122: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1664 - accuracy: 0.9330 - val_loss: 0.1457 - val_accuracy: 0.9312\n",
            "Epoch 123/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9336\n",
            "Epoch 123: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1547 - accuracy: 0.9336 - val_loss: 0.1469 - val_accuracy: 0.9325\n",
            "Epoch 124/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9314\n",
            "Epoch 124: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1499 - accuracy: 0.9314 - val_loss: 0.1401 - val_accuracy: 0.9362\n",
            "Epoch 125/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9329\n",
            "Epoch 125: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1460 - accuracy: 0.9328 - val_loss: 0.1395 - val_accuracy: 0.9366\n",
            "Epoch 126/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9326\n",
            "Epoch 126: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1519 - accuracy: 0.9326 - val_loss: 0.1374 - val_accuracy: 0.9344\n",
            "Epoch 127/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9323\n",
            "Epoch 127: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1534 - accuracy: 0.9323 - val_loss: 0.1466 - val_accuracy: 0.9308\n",
            "Epoch 128/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9327\n",
            "Epoch 128: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1534 - accuracy: 0.9327 - val_loss: 0.1514 - val_accuracy: 0.9299\n",
            "Epoch 129/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9315\n",
            "Epoch 129: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1981 - accuracy: 0.9315 - val_loss: 0.1709 - val_accuracy: 0.9305\n",
            "Epoch 130/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9331\n",
            "Epoch 130: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1507 - accuracy: 0.9331 - val_loss: 0.1410 - val_accuracy: 0.9356\n",
            "Epoch 131/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9332\n",
            "Epoch 131: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1474 - accuracy: 0.9332 - val_loss: 0.1409 - val_accuracy: 0.9340\n",
            "Epoch 132/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9330\n",
            "Epoch 132: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1435 - accuracy: 0.9330 - val_loss: 0.1612 - val_accuracy: 0.9280\n",
            "Epoch 133/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.9332\n",
            "Epoch 133: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1454 - accuracy: 0.9332 - val_loss: 0.1404 - val_accuracy: 0.9340\n",
            "Epoch 134/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9332\n",
            "Epoch 134: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1624 - accuracy: 0.9331 - val_loss: 0.2813 - val_accuracy: 0.9234\n",
            "Epoch 135/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9319\n",
            "Epoch 135: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1536 - accuracy: 0.9319 - val_loss: 0.1408 - val_accuracy: 0.9341\n",
            "Epoch 136/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9314\n",
            "Epoch 136: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1545 - accuracy: 0.9314 - val_loss: 0.1530 - val_accuracy: 0.9327\n",
            "Epoch 137/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 0.9314\n",
            "Epoch 137: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1572 - accuracy: 0.9314 - val_loss: 0.2308 - val_accuracy: 0.9185\n",
            "Epoch 138/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.3535 - accuracy: 0.9341\n",
            "Epoch 138: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3528 - accuracy: 0.9341 - val_loss: 0.1413 - val_accuracy: 0.9312\n",
            "Epoch 139/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9322\n",
            "Epoch 139: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1508 - accuracy: 0.9322 - val_loss: 0.1433 - val_accuracy: 0.9343\n",
            "Epoch 140/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9330\n",
            "Epoch 140: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1801 - accuracy: 0.9330 - val_loss: 0.1333 - val_accuracy: 0.9348\n",
            "Epoch 141/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9247\n",
            "Epoch 141: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1679 - accuracy: 0.9248 - val_loss: 0.1600 - val_accuracy: 0.9325\n",
            "Epoch 142/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.9290\n",
            "Epoch 142: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3803 - accuracy: 0.9290 - val_loss: 0.1420 - val_accuracy: 0.9213\n",
            "Epoch 143/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9275\n",
            "Epoch 143: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1759 - accuracy: 0.9276 - val_loss: 0.1432 - val_accuracy: 0.9329\n",
            "Epoch 144/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9332\n",
            "Epoch 144: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1549 - accuracy: 0.9332 - val_loss: 0.1333 - val_accuracy: 0.9340\n",
            "Epoch 145/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9331\n",
            "Epoch 145: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1480 - accuracy: 0.9330 - val_loss: 0.1506 - val_accuracy: 0.9256\n",
            "Epoch 146/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9331\n",
            "Epoch 146: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1640 - accuracy: 0.9331 - val_loss: 0.1327 - val_accuracy: 0.9365\n",
            "Epoch 147/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1464 - accuracy: 0.9337\n",
            "Epoch 147: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1464 - accuracy: 0.9337 - val_loss: 0.1431 - val_accuracy: 0.9346\n",
            "Epoch 148/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9320\n",
            "Epoch 148: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1499 - accuracy: 0.9320 - val_loss: 0.1701 - val_accuracy: 0.9341\n",
            "Epoch 149/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9327\n",
            "Epoch 149: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1794 - accuracy: 0.9327 - val_loss: 0.1406 - val_accuracy: 0.9345\n",
            "Epoch 150/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9320\n",
            "Epoch 150: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1605 - accuracy: 0.9320 - val_loss: 0.1521 - val_accuracy: 0.9315\n",
            "Epoch 151/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9317\n",
            "Epoch 151: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1493 - accuracy: 0.9317 - val_loss: 0.1498 - val_accuracy: 0.9335\n",
            "Epoch 152/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9319\n",
            "Epoch 152: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1490 - accuracy: 0.9319 - val_loss: 0.1939 - val_accuracy: 0.9268\n",
            "Epoch 153/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9321\n",
            "Epoch 153: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1531 - accuracy: 0.9321 - val_loss: 0.1452 - val_accuracy: 0.9344\n",
            "Epoch 154/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9318\n",
            "Epoch 154: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1632 - accuracy: 0.9318 - val_loss: 0.1595 - val_accuracy: 0.9154\n",
            "Epoch 155/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9330\n",
            "Epoch 155: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1567 - accuracy: 0.9330 - val_loss: 0.1428 - val_accuracy: 0.9342\n",
            "Epoch 156/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9325\n",
            "Epoch 156: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1838 - accuracy: 0.9325 - val_loss: 0.1505 - val_accuracy: 0.9278\n",
            "Epoch 157/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9306\n",
            "Epoch 157: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1584 - accuracy: 0.9306 - val_loss: 0.1357 - val_accuracy: 0.9355\n",
            "Epoch 158/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9319\n",
            "Epoch 158: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1647 - accuracy: 0.9319 - val_loss: 0.1342 - val_accuracy: 0.9343\n",
            "Epoch 159/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9324\n",
            "Epoch 159: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1514 - accuracy: 0.9324 - val_loss: 0.1427 - val_accuracy: 0.9319\n",
            "Epoch 160/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9311\n",
            "Epoch 160: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1874 - accuracy: 0.9311 - val_loss: 0.1492 - val_accuracy: 0.9290\n",
            "Epoch 161/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9306\n",
            "Epoch 161: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1515 - accuracy: 0.9306 - val_loss: 0.1578 - val_accuracy: 0.9336\n",
            "Epoch 162/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9316\n",
            "Epoch 162: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1508 - accuracy: 0.9316 - val_loss: 0.2702 - val_accuracy: 0.9301\n",
            "Epoch 163/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9309\n",
            "Epoch 163: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1971 - accuracy: 0.9308 - val_loss: 0.1703 - val_accuracy: 0.9133\n",
            "Epoch 164/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9289\n",
            "Epoch 164: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1621 - accuracy: 0.9289 - val_loss: 0.1381 - val_accuracy: 0.9340\n",
            "Epoch 165/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9301\n",
            "Epoch 165: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1666 - accuracy: 0.9301 - val_loss: 0.1608 - val_accuracy: 0.9262\n",
            "Epoch 166/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9310\n",
            "Epoch 166: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1539 - accuracy: 0.9310 - val_loss: 0.1662 - val_accuracy: 0.9315\n",
            "Epoch 167/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9289\n",
            "Epoch 167: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1569 - accuracy: 0.9289 - val_loss: 0.1419 - val_accuracy: 0.9321\n",
            "Epoch 168/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9317\n",
            "Epoch 168: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1492 - accuracy: 0.9317 - val_loss: 0.2156 - val_accuracy: 0.9204\n",
            "Epoch 169/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9310\n",
            "Epoch 169: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1491 - accuracy: 0.9310 - val_loss: 0.1731 - val_accuracy: 0.9332\n",
            "Epoch 170/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9300\n",
            "Epoch 170: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1667 - accuracy: 0.9300 - val_loss: 0.1574 - val_accuracy: 0.9324\n",
            "Epoch 171/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.9310\n",
            "Epoch 171: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1692 - accuracy: 0.9310 - val_loss: 0.1433 - val_accuracy: 0.9324\n",
            "Epoch 172/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9310\n",
            "Epoch 172: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1530 - accuracy: 0.9310 - val_loss: 0.1626 - val_accuracy: 0.9331\n",
            "Epoch 173/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9306\n",
            "Epoch 173: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1663 - accuracy: 0.9306 - val_loss: 0.1370 - val_accuracy: 0.9300\n",
            "Epoch 174/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1647 - accuracy: 0.9304\n",
            "Epoch 174: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1647 - accuracy: 0.9304 - val_loss: 0.1319 - val_accuracy: 0.9347\n",
            "Epoch 175/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9311\n",
            "Epoch 175: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1575 - accuracy: 0.9311 - val_loss: 0.1406 - val_accuracy: 0.9303\n",
            "Epoch 176/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.9302\n",
            "Epoch 176: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3616 - accuracy: 0.9302 - val_loss: 0.1348 - val_accuracy: 0.9358\n",
            "Epoch 177/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9309\n",
            "Epoch 177: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1569 - accuracy: 0.9309 - val_loss: 0.1790 - val_accuracy: 0.9327\n",
            "Epoch 178/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9293\n",
            "Epoch 178: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1839 - accuracy: 0.9293 - val_loss: 0.1667 - val_accuracy: 0.9338\n",
            "Epoch 179/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9317\n",
            "Epoch 179: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1667 - accuracy: 0.9318 - val_loss: 0.1364 - val_accuracy: 0.9346\n",
            "Epoch 180/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9308\n",
            "Epoch 180: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1491 - accuracy: 0.9308 - val_loss: 0.1307 - val_accuracy: 0.9356\n",
            "Epoch 181/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9310\n",
            "Epoch 181: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1624 - accuracy: 0.9310 - val_loss: 0.1444 - val_accuracy: 0.9329\n",
            "Epoch 182/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9304\n",
            "Epoch 182: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1571 - accuracy: 0.9304 - val_loss: 0.1557 - val_accuracy: 0.9328\n",
            "Epoch 183/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9308\n",
            "Epoch 183: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1609 - accuracy: 0.9308 - val_loss: 0.1378 - val_accuracy: 0.9330\n",
            "Epoch 184/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9307\n",
            "Epoch 184: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1650 - accuracy: 0.9307 - val_loss: 0.1349 - val_accuracy: 0.9359\n",
            "Epoch 185/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9324\n",
            "Epoch 185: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1620 - accuracy: 0.9324 - val_loss: 0.1340 - val_accuracy: 0.9343\n",
            "Epoch 186/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9239\n",
            "Epoch 186: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2119 - accuracy: 0.9239 - val_loss: 0.1520 - val_accuracy: 0.9272\n",
            "Epoch 187/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9307\n",
            "Epoch 187: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1792 - accuracy: 0.9307 - val_loss: 0.1661 - val_accuracy: 0.9261\n",
            "Epoch 188/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9306\n",
            "Epoch 188: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1659 - accuracy: 0.9306 - val_loss: 0.1445 - val_accuracy: 0.9335\n",
            "Epoch 189/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9316\n",
            "Epoch 189: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1494 - accuracy: 0.9316 - val_loss: 0.1492 - val_accuracy: 0.9286\n",
            "Epoch 190/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9310\n",
            "Epoch 190: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1631 - accuracy: 0.9310 - val_loss: 0.2231 - val_accuracy: 0.8629\n",
            "Epoch 191/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9307\n",
            "Epoch 191: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1613 - accuracy: 0.9307 - val_loss: 1.4198 - val_accuracy: 0.9095\n",
            "Epoch 192/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.9291\n",
            "Epoch 192: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2237 - accuracy: 0.9291 - val_loss: 0.1384 - val_accuracy: 0.9308\n",
            "Epoch 193/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9297\n",
            "Epoch 193: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1699 - accuracy: 0.9297 - val_loss: 0.1586 - val_accuracy: 0.9327\n",
            "Epoch 194/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9307\n",
            "Epoch 194: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1764 - accuracy: 0.9307 - val_loss: 0.2182 - val_accuracy: 0.9349\n",
            "Epoch 195/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9270\n",
            "Epoch 195: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1728 - accuracy: 0.9270 - val_loss: 0.1517 - val_accuracy: 0.9292\n",
            "Epoch 196/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9318\n",
            "Epoch 196: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1579 - accuracy: 0.9318 - val_loss: 0.1430 - val_accuracy: 0.9333\n",
            "Epoch 197/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1882 - accuracy: 0.9318\n",
            "Epoch 197: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1882 - accuracy: 0.9318 - val_loss: 0.1550 - val_accuracy: 0.9306\n",
            "Epoch 198/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9309\n",
            "Epoch 198: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1547 - accuracy: 0.9309 - val_loss: 0.1341 - val_accuracy: 0.9349\n",
            "Epoch 199/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9293\n",
            "Epoch 199: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1836 - accuracy: 0.9292 - val_loss: 0.1548 - val_accuracy: 0.9284\n",
            "Epoch 200/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 0.9303\n",
            "Epoch 200: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1632 - accuracy: 0.9303 - val_loss: 0.1331 - val_accuracy: 0.9360\n",
            "Epoch 201/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9317\n",
            "Epoch 201: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1666 - accuracy: 0.9317 - val_loss: 0.1476 - val_accuracy: 0.9332\n",
            "Epoch 202/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9320\n",
            "Epoch 202: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1690 - accuracy: 0.9320 - val_loss: 0.1664 - val_accuracy: 0.9222\n",
            "Epoch 203/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9298\n",
            "Epoch 203: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1556 - accuracy: 0.9298 - val_loss: 0.1748 - val_accuracy: 0.9300\n",
            "Epoch 204/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9310\n",
            "Epoch 204: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1596 - accuracy: 0.9310 - val_loss: 0.1477 - val_accuracy: 0.9265\n",
            "Epoch 205/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9310\n",
            "Epoch 205: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1568 - accuracy: 0.9310 - val_loss: 0.1789 - val_accuracy: 0.9184\n",
            "Epoch 206/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9299\n",
            "Epoch 206: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1503 - accuracy: 0.9299 - val_loss: 0.1494 - val_accuracy: 0.9303\n",
            "Epoch 207/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 0.9315\n",
            "Epoch 207: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1723 - accuracy: 0.9316 - val_loss: 0.1512 - val_accuracy: 0.9229\n",
            "Epoch 208/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.9325\n",
            "Epoch 208: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1848 - accuracy: 0.9325 - val_loss: 0.1501 - val_accuracy: 0.9325\n",
            "Epoch 209/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.9305\n",
            "Epoch 209: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2928 - accuracy: 0.9305 - val_loss: 0.1331 - val_accuracy: 0.9333\n",
            "Epoch 210/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9306\n",
            "Epoch 210: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1613 - accuracy: 0.9306 - val_loss: 0.1461 - val_accuracy: 0.9244\n",
            "Epoch 211/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9310\n",
            "Epoch 211: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1675 - accuracy: 0.9310 - val_loss: 0.1860 - val_accuracy: 0.9198\n",
            "Epoch 212/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9304\n",
            "Epoch 212: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1673 - accuracy: 0.9304 - val_loss: 0.1614 - val_accuracy: 0.9169\n",
            "Epoch 213/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9305\n",
            "Epoch 213: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1973 - accuracy: 0.9305 - val_loss: 0.1640 - val_accuracy: 0.9195\n",
            "Epoch 214/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9305\n",
            "Epoch 214: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1566 - accuracy: 0.9305 - val_loss: 0.1636 - val_accuracy: 0.9317\n",
            "Epoch 215/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9317\n",
            "Epoch 215: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1612 - accuracy: 0.9317 - val_loss: 0.1707 - val_accuracy: 0.9236\n",
            "Epoch 216/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9291\n",
            "Epoch 216: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2100 - accuracy: 0.9291 - val_loss: 0.1447 - val_accuracy: 0.9320\n",
            "Epoch 217/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9309\n",
            "Epoch 217: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1578 - accuracy: 0.9309 - val_loss: 0.1827 - val_accuracy: 0.9300\n",
            "Epoch 218/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9319\n",
            "Epoch 218: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1548 - accuracy: 0.9319 - val_loss: 0.1699 - val_accuracy: 0.9179\n",
            "Epoch 219/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9296\n",
            "Epoch 219: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1662 - accuracy: 0.9296 - val_loss: 0.1412 - val_accuracy: 0.9326\n",
            "Epoch 220/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9306\n",
            "Epoch 220: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1552 - accuracy: 0.9306 - val_loss: 0.1476 - val_accuracy: 0.9283\n",
            "Epoch 221/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9308\n",
            "Epoch 221: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1796 - accuracy: 0.9308 - val_loss: 0.1346 - val_accuracy: 0.9349\n",
            "Epoch 222/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9314\n",
            "Epoch 222: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1635 - accuracy: 0.9314 - val_loss: 0.1397 - val_accuracy: 0.9322\n",
            "Epoch 223/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9294\n",
            "Epoch 223: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1593 - accuracy: 0.9293 - val_loss: 0.1474 - val_accuracy: 0.9313\n",
            "Epoch 224/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9314\n",
            "Epoch 224: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1814 - accuracy: 0.9314 - val_loss: 0.1369 - val_accuracy: 0.9353\n",
            "Epoch 225/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9295\n",
            "Epoch 225: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1803 - accuracy: 0.9295 - val_loss: 0.2174 - val_accuracy: 0.9248\n",
            "Epoch 226/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9312\n",
            "Epoch 226: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1683 - accuracy: 0.9312 - val_loss: 0.1431 - val_accuracy: 0.9304\n",
            "Epoch 227/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9306\n",
            "Epoch 227: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1556 - accuracy: 0.9307 - val_loss: 0.1509 - val_accuracy: 0.9277\n",
            "Epoch 228/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9307\n",
            "Epoch 228: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1601 - accuracy: 0.9307 - val_loss: 0.1569 - val_accuracy: 0.9264\n",
            "Epoch 229/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.9306\n",
            "Epoch 229: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 0.1416 - val_accuracy: 0.9301\n",
            "Epoch 230/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9303\n",
            "Epoch 230: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1664 - accuracy: 0.9304 - val_loss: 0.1436 - val_accuracy: 0.9328\n",
            "Epoch 231/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9301\n",
            "Epoch 231: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1903 - accuracy: 0.9301 - val_loss: 0.1503 - val_accuracy: 0.9325\n",
            "Epoch 232/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9305\n",
            "Epoch 232: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1582 - accuracy: 0.9305 - val_loss: 0.1489 - val_accuracy: 0.9280\n",
            "Epoch 233/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9311\n",
            "Epoch 233: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1911 - accuracy: 0.9311 - val_loss: 0.1332 - val_accuracy: 0.9357\n",
            "Epoch 234/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9297\n",
            "Epoch 234: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2049 - accuracy: 0.9297 - val_loss: 0.1531 - val_accuracy: 0.9276\n",
            "Epoch 235/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9307\n",
            "Epoch 235: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1558 - accuracy: 0.9306 - val_loss: 0.1471 - val_accuracy: 0.9314\n",
            "Epoch 236/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9302\n",
            "Epoch 236: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1605 - accuracy: 0.9302 - val_loss: 0.1913 - val_accuracy: 0.9261\n",
            "Epoch 237/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1942 - accuracy: 0.9313\n",
            "Epoch 237: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1940 - accuracy: 0.9313 - val_loss: 0.1399 - val_accuracy: 0.9347\n",
            "Epoch 238/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9315\n",
            "Epoch 238: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1727 - accuracy: 0.9315 - val_loss: 0.1507 - val_accuracy: 0.9329\n",
            "Epoch 239/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9280\n",
            "Epoch 239: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2143 - accuracy: 0.9280 - val_loss: 0.1582 - val_accuracy: 0.9323\n",
            "Epoch 240/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9295\n",
            "Epoch 240: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1710 - accuracy: 0.9295 - val_loss: 0.1945 - val_accuracy: 0.9075\n",
            "Epoch 241/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9299\n",
            "Epoch 241: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1704 - accuracy: 0.9298 - val_loss: 0.1432 - val_accuracy: 0.9335\n",
            "Epoch 242/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9303\n",
            "Epoch 242: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1544 - accuracy: 0.9303 - val_loss: 0.1590 - val_accuracy: 0.9261\n",
            "Epoch 243/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.9300\n",
            "Epoch 243: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1684 - accuracy: 0.9299 - val_loss: 0.1418 - val_accuracy: 0.9312\n",
            "Epoch 244/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9296\n",
            "Epoch 244: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1652 - accuracy: 0.9296 - val_loss: 0.1531 - val_accuracy: 0.9310\n",
            "Epoch 245/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9304\n",
            "Epoch 245: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1665 - accuracy: 0.9304 - val_loss: 0.1394 - val_accuracy: 0.9339\n",
            "Epoch 246/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9300\n",
            "Epoch 246: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1705 - accuracy: 0.9300 - val_loss: 0.1406 - val_accuracy: 0.9302\n",
            "Epoch 247/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9297\n",
            "Epoch 247: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1875 - accuracy: 0.9298 - val_loss: 0.1391 - val_accuracy: 0.9356\n",
            "Epoch 248/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9310\n",
            "Epoch 248: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2190 - accuracy: 0.9310 - val_loss: 0.1556 - val_accuracy: 0.9298\n",
            "Epoch 249/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9303\n",
            "Epoch 249: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1569 - accuracy: 0.9303 - val_loss: 0.1411 - val_accuracy: 0.9341\n",
            "Epoch 250/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9315\n",
            "Epoch 250: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1619 - accuracy: 0.9315 - val_loss: 0.1537 - val_accuracy: 0.9301\n",
            "Epoch 251/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9303\n",
            "Epoch 251: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1620 - accuracy: 0.9303 - val_loss: 0.1497 - val_accuracy: 0.9290\n",
            "Epoch 252/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9282\n",
            "Epoch 252: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1668 - accuracy: 0.9282 - val_loss: 0.1720 - val_accuracy: 0.9190\n",
            "Epoch 253/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9300\n",
            "Epoch 253: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1907 - accuracy: 0.9300 - val_loss: 0.1439 - val_accuracy: 0.9307\n",
            "Epoch 254/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9298\n",
            "Epoch 254: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1631 - accuracy: 0.9298 - val_loss: 0.1772 - val_accuracy: 0.9318\n",
            "Epoch 255/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9311\n",
            "Epoch 255: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1669 - accuracy: 0.9309 - val_loss: 0.2058 - val_accuracy: 0.9005\n",
            "Epoch 256/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9306\n",
            "Epoch 256: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1896 - accuracy: 0.9306 - val_loss: 0.1346 - val_accuracy: 0.9342\n",
            "Epoch 257/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9313\n",
            "Epoch 257: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1772 - accuracy: 0.9313 - val_loss: 0.1491 - val_accuracy: 0.9348\n",
            "Epoch 258/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9324\n",
            "Epoch 258: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1792 - accuracy: 0.9324 - val_loss: 0.1356 - val_accuracy: 0.9336\n",
            "Epoch 259/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9324\n",
            "Epoch 259: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1790 - accuracy: 0.9324 - val_loss: 0.1313 - val_accuracy: 0.9357\n",
            "Epoch 260/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9321\n",
            "Epoch 260: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1559 - accuracy: 0.9321 - val_loss: 0.1513 - val_accuracy: 0.9219\n",
            "Epoch 261/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9308\n",
            "Epoch 261: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1615 - accuracy: 0.9307 - val_loss: 0.2012 - val_accuracy: 0.9195\n",
            "Epoch 262/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9301\n",
            "Epoch 262: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1780 - accuracy: 0.9301 - val_loss: 0.1432 - val_accuracy: 0.9287\n",
            "Epoch 263/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 0.9302\n",
            "Epoch 263: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1632 - accuracy: 0.9301 - val_loss: 0.1507 - val_accuracy: 0.9316\n",
            "Epoch 264/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9318\n",
            "Epoch 264: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1637 - accuracy: 0.9318 - val_loss: 0.1425 - val_accuracy: 0.9283\n",
            "Epoch 265/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9317\n",
            "Epoch 265: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1539 - accuracy: 0.9318 - val_loss: 0.1370 - val_accuracy: 0.9341\n",
            "Epoch 266/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9297\n",
            "Epoch 266: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1597 - accuracy: 0.9297 - val_loss: 0.1429 - val_accuracy: 0.9337\n",
            "Epoch 267/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9320\n",
            "Epoch 267: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2202 - accuracy: 0.9320 - val_loss: 0.1402 - val_accuracy: 0.9336\n",
            "Epoch 268/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9315\n",
            "Epoch 268: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1957 - accuracy: 0.9315 - val_loss: 0.1418 - val_accuracy: 0.9371\n",
            "Epoch 269/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1708 - accuracy: 0.9321\n",
            "Epoch 269: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1706 - accuracy: 0.9321 - val_loss: 0.1554 - val_accuracy: 0.9301\n",
            "Epoch 270/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9311\n",
            "Epoch 270: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1532 - accuracy: 0.9311 - val_loss: 0.1521 - val_accuracy: 0.9325\n",
            "Epoch 271/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9319\n",
            "Epoch 271: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1769 - accuracy: 0.9319 - val_loss: 0.1509 - val_accuracy: 0.9343\n",
            "Epoch 272/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9327\n",
            "Epoch 272: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1766 - accuracy: 0.9327 - val_loss: 0.1344 - val_accuracy: 0.9359\n",
            "Epoch 273/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.9294\n",
            "Epoch 273: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2858 - accuracy: 0.9294 - val_loss: 0.1492 - val_accuracy: 0.9323\n",
            "Epoch 274/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9315\n",
            "Epoch 274: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1580 - accuracy: 0.9315 - val_loss: 0.1558 - val_accuracy: 0.9330\n",
            "Epoch 275/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9298\n",
            "Epoch 275: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1616 - accuracy: 0.9298 - val_loss: 0.1566 - val_accuracy: 0.9313\n",
            "Epoch 276/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9307\n",
            "Epoch 276: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1859 - accuracy: 0.9307 - val_loss: 0.1424 - val_accuracy: 0.9345\n",
            "Epoch 277/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1656 - accuracy: 0.9312\n",
            "Epoch 277: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1656 - accuracy: 0.9312 - val_loss: 0.1374 - val_accuracy: 0.9326\n",
            "Epoch 278/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9312\n",
            "Epoch 278: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1568 - accuracy: 0.9312 - val_loss: 0.1616 - val_accuracy: 0.9341\n",
            "Epoch 279/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9303\n",
            "Epoch 279: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1699 - accuracy: 0.9303 - val_loss: 0.1428 - val_accuracy: 0.9326\n",
            "Epoch 280/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9308\n",
            "Epoch 280: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1867 - accuracy: 0.9308 - val_loss: 0.1994 - val_accuracy: 0.9017\n",
            "Epoch 281/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1968 - accuracy: 0.9297\n",
            "Epoch 281: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1968 - accuracy: 0.9297 - val_loss: 0.1422 - val_accuracy: 0.9319\n",
            "Epoch 282/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9316\n",
            "Epoch 282: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1944 - accuracy: 0.9316 - val_loss: 0.1496 - val_accuracy: 0.9312\n",
            "Epoch 283/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9224\n",
            "Epoch 283: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1990 - accuracy: 0.9221 - val_loss: 0.2637 - val_accuracy: 0.8526\n",
            "Epoch 284/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9285\n",
            "Epoch 284: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1626 - accuracy: 0.9285 - val_loss: 0.1593 - val_accuracy: 0.9204\n",
            "Epoch 285/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9306\n",
            "Epoch 285: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1803 - accuracy: 0.9306 - val_loss: 0.1502 - val_accuracy: 0.9298\n",
            "Epoch 286/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9299\n",
            "Epoch 286: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1627 - accuracy: 0.9299 - val_loss: 0.3966 - val_accuracy: 0.9224\n",
            "Epoch 287/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9292\n",
            "Epoch 287: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1749 - accuracy: 0.9292 - val_loss: 0.1396 - val_accuracy: 0.9312\n",
            "Epoch 288/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9302\n",
            "Epoch 288: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1835 - accuracy: 0.9302 - val_loss: 0.1344 - val_accuracy: 0.9332\n",
            "Epoch 289/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9292\n",
            "Epoch 289: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1672 - accuracy: 0.9292 - val_loss: 0.1747 - val_accuracy: 0.9317\n",
            "Epoch 290/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9301\n",
            "Epoch 290: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 18ms/step - loss: 0.1630 - accuracy: 0.9301 - val_loss: 0.1396 - val_accuracy: 0.9318\n",
            "Epoch 291/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9310\n",
            "Epoch 291: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1793 - accuracy: 0.9309 - val_loss: 0.1556 - val_accuracy: 0.9298\n",
            "Epoch 292/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.9308\n",
            "Epoch 292: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1827 - accuracy: 0.9308 - val_loss: 0.1614 - val_accuracy: 0.9332\n",
            "Epoch 293/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9306\n",
            "Epoch 293: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1797 - accuracy: 0.9306 - val_loss: 0.1332 - val_accuracy: 0.9355\n",
            "Epoch 294/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9309\n",
            "Epoch 294: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1635 - accuracy: 0.9309 - val_loss: 0.1391 - val_accuracy: 0.9352\n",
            "Epoch 295/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9288\n",
            "Epoch 295: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1909 - accuracy: 0.9288 - val_loss: 0.1645 - val_accuracy: 0.9289\n",
            "Epoch 296/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9298\n",
            "Epoch 296: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1776 - accuracy: 0.9298 - val_loss: 0.1425 - val_accuracy: 0.9314\n",
            "Epoch 297/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9314\n",
            "Epoch 297: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1568 - accuracy: 0.9314 - val_loss: 0.1563 - val_accuracy: 0.9270\n",
            "Epoch 298/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9311\n",
            "Epoch 298: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1930 - accuracy: 0.9311 - val_loss: 0.1540 - val_accuracy: 0.9281\n",
            "Epoch 299/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.9301\n",
            "Epoch 299: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1890 - accuracy: 0.9302 - val_loss: 0.2207 - val_accuracy: 0.9270\n",
            "Epoch 300/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9296\n",
            "Epoch 300: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1783 - accuracy: 0.9296 - val_loss: 0.1541 - val_accuracy: 0.9188\n",
            "Epoch 301/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9287\n",
            "Epoch 301: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1795 - accuracy: 0.9287 - val_loss: 0.1367 - val_accuracy: 0.9333\n",
            "Epoch 302/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2076 - accuracy: 0.9292\n",
            "Epoch 302: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2076 - accuracy: 0.9292 - val_loss: 0.1349 - val_accuracy: 0.9340\n",
            "Epoch 303/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9308\n",
            "Epoch 303: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1585 - accuracy: 0.9308 - val_loss: 0.1668 - val_accuracy: 0.9323\n",
            "Epoch 304/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9294\n",
            "Epoch 304: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1660 - accuracy: 0.9294 - val_loss: 0.1315 - val_accuracy: 0.9354\n",
            "Epoch 305/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9282\n",
            "Epoch 305: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2304 - accuracy: 0.9281 - val_loss: 0.1426 - val_accuracy: 0.9242\n",
            "Epoch 306/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9293\n",
            "Epoch 306: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1682 - accuracy: 0.9293 - val_loss: 0.1662 - val_accuracy: 0.9209\n",
            "Epoch 307/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1937 - accuracy: 0.9291\n",
            "Epoch 307: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1936 - accuracy: 0.9291 - val_loss: 0.1755 - val_accuracy: 0.9322\n",
            "Epoch 308/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9280\n",
            "Epoch 308: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1881 - accuracy: 0.9280 - val_loss: 0.1375 - val_accuracy: 0.9342\n",
            "Epoch 309/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9276\n",
            "Epoch 309: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1629 - accuracy: 0.9276 - val_loss: 0.1404 - val_accuracy: 0.9282\n",
            "Epoch 310/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 0.9291\n",
            "Epoch 310: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1673 - accuracy: 0.9291 - val_loss: 0.1496 - val_accuracy: 0.9224\n",
            "Epoch 311/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9285\n",
            "Epoch 311: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1737 - accuracy: 0.9285 - val_loss: 0.1677 - val_accuracy: 0.9283\n",
            "Epoch 312/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9285\n",
            "Epoch 312: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1605 - accuracy: 0.9284 - val_loss: 0.1452 - val_accuracy: 0.9315\n",
            "Epoch 313/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1743 - accuracy: 0.9270\n",
            "Epoch 313: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1743 - accuracy: 0.9270 - val_loss: 0.1552 - val_accuracy: 0.9223\n",
            "Epoch 314/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.9298\n",
            "Epoch 314: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1953 - accuracy: 0.9298 - val_loss: 0.1645 - val_accuracy: 0.9324\n",
            "Epoch 315/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2141 - accuracy: 0.9282\n",
            "Epoch 315: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2139 - accuracy: 0.9282 - val_loss: 0.1423 - val_accuracy: 0.9295\n",
            "Epoch 316/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9279\n",
            "Epoch 316: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1617 - accuracy: 0.9279 - val_loss: 0.5841 - val_accuracy: 0.9324\n",
            "Epoch 317/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9288\n",
            "Epoch 317: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1978 - accuracy: 0.9288 - val_loss: 0.1380 - val_accuracy: 0.9318\n",
            "Epoch 318/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1624 - accuracy: 0.9289\n",
            "Epoch 318: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1624 - accuracy: 0.9289 - val_loss: 0.1351 - val_accuracy: 0.9328\n",
            "Epoch 319/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.9290\n",
            "Epoch 319: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1653 - accuracy: 0.9290 - val_loss: 0.1426 - val_accuracy: 0.9318\n",
            "Epoch 320/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9287\n",
            "Epoch 320: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1727 - accuracy: 0.9286 - val_loss: 0.1947 - val_accuracy: 0.9299\n",
            "Epoch 321/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9279\n",
            "Epoch 321: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1794 - accuracy: 0.9278 - val_loss: 0.1529 - val_accuracy: 0.9222\n",
            "Epoch 322/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1777 - accuracy: 0.9273\n",
            "Epoch 322: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1777 - accuracy: 0.9272 - val_loss: 0.1380 - val_accuracy: 0.9324\n",
            "Epoch 323/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9287\n",
            "Epoch 323: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1714 - accuracy: 0.9287 - val_loss: 0.1341 - val_accuracy: 0.9359\n",
            "Epoch 324/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.3568 - accuracy: 0.9271\n",
            "Epoch 324: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3568 - accuracy: 0.9271 - val_loss: 0.1432 - val_accuracy: 0.9332\n",
            "Epoch 325/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.9254\n",
            "Epoch 325: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.4105 - accuracy: 0.9254 - val_loss: 1.0762 - val_accuracy: 0.9007\n",
            "Epoch 326/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.9198\n",
            "Epoch 326: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3115 - accuracy: 0.9198 - val_loss: 0.1493 - val_accuracy: 0.9290\n",
            "Epoch 327/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9262\n",
            "Epoch 327: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1589 - accuracy: 0.9262 - val_loss: 0.1419 - val_accuracy: 0.9310\n",
            "Epoch 328/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9281\n",
            "Epoch 328: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2087 - accuracy: 0.9281 - val_loss: 0.1518 - val_accuracy: 0.9279\n",
            "Epoch 329/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9271\n",
            "Epoch 329: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1799 - accuracy: 0.9272 - val_loss: 0.1509 - val_accuracy: 0.9311\n",
            "Epoch 330/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 0.9294\n",
            "Epoch 330: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1534 - accuracy: 0.9294 - val_loss: 0.1439 - val_accuracy: 0.9328\n",
            "Epoch 331/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9304\n",
            "Epoch 331: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1790 - accuracy: 0.9304 - val_loss: 0.1523 - val_accuracy: 0.9257\n",
            "Epoch 332/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9243\n",
            "Epoch 332: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1819 - accuracy: 0.9243 - val_loss: 0.1576 - val_accuracy: 0.9292\n",
            "Epoch 333/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9288\n",
            "Epoch 333: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1971 - accuracy: 0.9289 - val_loss: 0.1435 - val_accuracy: 0.9298\n",
            "Epoch 334/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9277\n",
            "Epoch 334: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1693 - accuracy: 0.9278 - val_loss: 0.1499 - val_accuracy: 0.9326\n",
            "Epoch 335/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9278\n",
            "Epoch 335: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1772 - accuracy: 0.9278 - val_loss: 0.1473 - val_accuracy: 0.9306\n",
            "Epoch 336/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9264\n",
            "Epoch 336: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1727 - accuracy: 0.9264 - val_loss: 0.1487 - val_accuracy: 0.9219\n",
            "Epoch 337/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9282\n",
            "Epoch 337: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1771 - accuracy: 0.9281 - val_loss: 0.3121 - val_accuracy: 0.9311\n",
            "Epoch 338/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9262\n",
            "Epoch 338: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1738 - accuracy: 0.9262 - val_loss: 0.2676 - val_accuracy: 0.9284\n",
            "Epoch 339/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.9263\n",
            "Epoch 339: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1791 - accuracy: 0.9263 - val_loss: 0.1419 - val_accuracy: 0.9302\n",
            "Epoch 340/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9277\n",
            "Epoch 340: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1729 - accuracy: 0.9277 - val_loss: 0.1401 - val_accuracy: 0.9291\n",
            "Epoch 341/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9259\n",
            "Epoch 341: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2670 - accuracy: 0.9259 - val_loss: 0.1511 - val_accuracy: 0.9274\n",
            "Epoch 342/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 0.9259\n",
            "Epoch 342: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1862 - accuracy: 0.9259 - val_loss: 0.1415 - val_accuracy: 0.9314\n",
            "Epoch 343/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9259\n",
            "Epoch 343: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1747 - accuracy: 0.9259 - val_loss: 0.1442 - val_accuracy: 0.9314\n",
            "Epoch 344/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9253\n",
            "Epoch 344: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1793 - accuracy: 0.9254 - val_loss: 0.3791 - val_accuracy: 0.9352\n",
            "Epoch 345/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9274\n",
            "Epoch 345: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1766 - accuracy: 0.9274 - val_loss: 0.1393 - val_accuracy: 0.9308\n",
            "Epoch 346/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9262\n",
            "Epoch 346: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1975 - accuracy: 0.9262 - val_loss: 0.1536 - val_accuracy: 0.9257\n",
            "Epoch 347/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.9243\n",
            "Epoch 347: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2234 - accuracy: 0.9244 - val_loss: 0.1438 - val_accuracy: 0.9282\n",
            "Epoch 348/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9268\n",
            "Epoch 348: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2747 - accuracy: 0.9268 - val_loss: 0.1478 - val_accuracy: 0.9309\n",
            "Epoch 349/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1866 - accuracy: 0.9252\n",
            "Epoch 349: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1867 - accuracy: 0.9252 - val_loss: 0.1815 - val_accuracy: 0.9013\n",
            "Epoch 350/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9233\n",
            "Epoch 350: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1722 - accuracy: 0.9233 - val_loss: 0.1534 - val_accuracy: 0.9278\n",
            "Epoch 351/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.9236\n",
            "Epoch 351: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1757 - accuracy: 0.9236 - val_loss: 0.1544 - val_accuracy: 0.9274\n",
            "Epoch 352/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1725 - accuracy: 0.9268\n",
            "Epoch 352: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1725 - accuracy: 0.9268 - val_loss: 0.1721 - val_accuracy: 0.9319\n",
            "Epoch 353/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9245\n",
            "Epoch 353: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1810 - accuracy: 0.9245 - val_loss: 0.1837 - val_accuracy: 0.9279\n",
            "Epoch 354/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9255\n",
            "Epoch 354: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1705 - accuracy: 0.9255 - val_loss: 0.1500 - val_accuracy: 0.9294\n",
            "Epoch 355/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9254\n",
            "Epoch 355: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2091 - accuracy: 0.9253 - val_loss: 0.1606 - val_accuracy: 0.9232\n",
            "Epoch 356/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9280\n",
            "Epoch 356: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1711 - accuracy: 0.9280 - val_loss: 0.1578 - val_accuracy: 0.9230\n",
            "Epoch 357/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9251\n",
            "Epoch 357: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1664 - accuracy: 0.9251 - val_loss: 0.1681 - val_accuracy: 0.9292\n",
            "Epoch 358/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9271\n",
            "Epoch 358: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1874 - accuracy: 0.9271 - val_loss: 0.1517 - val_accuracy: 0.9247\n",
            "Epoch 359/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9248\n",
            "Epoch 359: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1915 - accuracy: 0.9248 - val_loss: 0.1615 - val_accuracy: 0.9195\n",
            "Epoch 360/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9241\n",
            "Epoch 360: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1740 - accuracy: 0.9241 - val_loss: 0.1669 - val_accuracy: 0.9266\n",
            "Epoch 361/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9242\n",
            "Epoch 361: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1780 - accuracy: 0.9242 - val_loss: 0.1440 - val_accuracy: 0.9269\n",
            "Epoch 362/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9246\n",
            "Epoch 362: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1931 - accuracy: 0.9247 - val_loss: 0.1818 - val_accuracy: 0.9288\n",
            "Epoch 363/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 0.9258\n",
            "Epoch 363: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1698 - accuracy: 0.9258 - val_loss: 0.1442 - val_accuracy: 0.9268\n",
            "Epoch 364/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9286\n",
            "Epoch 364: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2032 - accuracy: 0.9286 - val_loss: 0.1465 - val_accuracy: 0.9317\n",
            "Epoch 365/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9266\n",
            "Epoch 365: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2381 - accuracy: 0.9266 - val_loss: 0.1469 - val_accuracy: 0.9288\n",
            "Epoch 366/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9252\n",
            "Epoch 366: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1778 - accuracy: 0.9253 - val_loss: 0.1722 - val_accuracy: 0.9264\n",
            "Epoch 367/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1788 - accuracy: 0.9262\n",
            "Epoch 367: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1787 - accuracy: 0.9262 - val_loss: 0.1560 - val_accuracy: 0.9313\n",
            "Epoch 368/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.9246\n",
            "Epoch 368: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2318 - accuracy: 0.9246 - val_loss: 0.1671 - val_accuracy: 0.9253\n",
            "Epoch 369/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9234\n",
            "Epoch 369: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3298 - accuracy: 0.9234 - val_loss: 0.1582 - val_accuracy: 0.9224\n",
            "Epoch 370/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9254\n",
            "Epoch 370: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1785 - accuracy: 0.9254 - val_loss: 0.1764 - val_accuracy: 0.9256\n",
            "Epoch 371/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9151\n",
            "Epoch 371: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2195 - accuracy: 0.9151 - val_loss: 0.1685 - val_accuracy: 0.9286\n",
            "Epoch 372/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9208\n",
            "Epoch 372: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1912 - accuracy: 0.9208 - val_loss: 0.1644 - val_accuracy: 0.9241\n",
            "Epoch 373/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9226\n",
            "Epoch 373: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1843 - accuracy: 0.9226 - val_loss: 0.1484 - val_accuracy: 0.9303\n",
            "Epoch 374/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1940 - accuracy: 0.9247\n",
            "Epoch 374: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1940 - accuracy: 0.9247 - val_loss: 1.3959 - val_accuracy: 0.8925\n",
            "Epoch 375/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9265\n",
            "Epoch 375: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1664 - accuracy: 0.9265 - val_loss: 0.1447 - val_accuracy: 0.9279\n",
            "Epoch 376/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1775 - accuracy: 0.9259\n",
            "Epoch 376: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1775 - accuracy: 0.9258 - val_loss: 0.1435 - val_accuracy: 0.9320\n",
            "Epoch 377/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1831 - accuracy: 0.9243\n",
            "Epoch 377: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1831 - accuracy: 0.9243 - val_loss: 0.1477 - val_accuracy: 0.9293\n",
            "Epoch 378/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9275\n",
            "Epoch 378: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1751 - accuracy: 0.9275 - val_loss: 0.1545 - val_accuracy: 0.9252\n",
            "Epoch 379/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9268\n",
            "Epoch 379: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1712 - accuracy: 0.9269 - val_loss: 0.1485 - val_accuracy: 0.9299\n",
            "Epoch 380/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9262\n",
            "Epoch 380: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1722 - accuracy: 0.9262 - val_loss: 0.1685 - val_accuracy: 0.9251\n",
            "Epoch 381/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9277\n",
            "Epoch 381: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1622 - accuracy: 0.9277 - val_loss: 0.1426 - val_accuracy: 0.9308\n",
            "Epoch 382/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9258\n",
            "Epoch 382: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1746 - accuracy: 0.9258 - val_loss: 0.1394 - val_accuracy: 0.9328\n",
            "Epoch 383/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9279\n",
            "Epoch 383: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1704 - accuracy: 0.9280 - val_loss: 0.1575 - val_accuracy: 0.9305\n",
            "Epoch 384/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2522 - accuracy: 0.9263\n",
            "Epoch 384: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2519 - accuracy: 0.9264 - val_loss: 0.1751 - val_accuracy: 0.9302\n",
            "Epoch 385/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9259\n",
            "Epoch 385: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1726 - accuracy: 0.9259 - val_loss: 0.1578 - val_accuracy: 0.9256\n",
            "Epoch 386/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.9253\n",
            "Epoch 386: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1692 - accuracy: 0.9253 - val_loss: 0.2343 - val_accuracy: 0.9280\n",
            "Epoch 387/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.9262\n",
            "Epoch 387: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1816 - accuracy: 0.9262 - val_loss: 0.1460 - val_accuracy: 0.9283\n",
            "Epoch 388/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1831 - accuracy: 0.9259\n",
            "Epoch 388: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1831 - accuracy: 0.9259 - val_loss: 0.1602 - val_accuracy: 0.9302\n",
            "Epoch 389/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9252\n",
            "Epoch 389: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1783 - accuracy: 0.9252 - val_loss: 0.1512 - val_accuracy: 0.9216\n",
            "Epoch 390/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9266\n",
            "Epoch 390: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2385 - accuracy: 0.9266 - val_loss: 0.1436 - val_accuracy: 0.9288\n",
            "Epoch 391/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9284\n",
            "Epoch 391: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2562 - accuracy: 0.9284 - val_loss: 0.1461 - val_accuracy: 0.9290\n",
            "Epoch 392/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9238\n",
            "Epoch 392: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1838 - accuracy: 0.9238 - val_loss: 0.1561 - val_accuracy: 0.9218\n",
            "Epoch 393/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9273\n",
            "Epoch 393: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1914 - accuracy: 0.9273 - val_loss: 0.1836 - val_accuracy: 0.9305\n",
            "Epoch 394/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9280\n",
            "Epoch 394: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1703 - accuracy: 0.9280 - val_loss: 0.1396 - val_accuracy: 0.9318\n",
            "Epoch 395/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9283\n",
            "Epoch 395: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1910 - accuracy: 0.9282 - val_loss: 0.1624 - val_accuracy: 0.9293\n",
            "Epoch 396/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9255\n",
            "Epoch 396: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1795 - accuracy: 0.9255 - val_loss: 0.1450 - val_accuracy: 0.9304\n",
            "Epoch 397/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9283\n",
            "Epoch 397: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1806 - accuracy: 0.9283 - val_loss: 0.1549 - val_accuracy: 0.9310\n",
            "Epoch 398/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9281\n",
            "Epoch 398: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1726 - accuracy: 0.9281 - val_loss: 0.1747 - val_accuracy: 0.9306\n",
            "Epoch 399/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.9247\n",
            "Epoch 399: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1777 - accuracy: 0.9247 - val_loss: 0.1512 - val_accuracy: 0.9312\n",
            "Epoch 400/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9276\n",
            "Epoch 400: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1737 - accuracy: 0.9277 - val_loss: 0.1483 - val_accuracy: 0.9261\n",
            "Epoch 401/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9255\n",
            "Epoch 401: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1775 - accuracy: 0.9255 - val_loss: 0.2381 - val_accuracy: 0.9245\n",
            "Epoch 402/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.9233\n",
            "Epoch 402: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3610 - accuracy: 0.9233 - val_loss: 0.1383 - val_accuracy: 0.9303\n",
            "Epoch 403/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9263\n",
            "Epoch 403: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1890 - accuracy: 0.9263 - val_loss: 0.1519 - val_accuracy: 0.9289\n",
            "Epoch 404/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9268\n",
            "Epoch 404: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1951 - accuracy: 0.9268 - val_loss: 0.1452 - val_accuracy: 0.9291\n",
            "Epoch 405/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9225\n",
            "Epoch 405: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1942 - accuracy: 0.9225 - val_loss: 0.1445 - val_accuracy: 0.9309\n",
            "Epoch 406/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.9224\n",
            "Epoch 406: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1950 - accuracy: 0.9224 - val_loss: 0.2081 - val_accuracy: 0.9271\n",
            "Epoch 407/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9233\n",
            "Epoch 407: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2145 - accuracy: 0.9233 - val_loss: 0.1424 - val_accuracy: 0.9316\n",
            "Epoch 408/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9218\n",
            "Epoch 408: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2058 - accuracy: 0.9218 - val_loss: 0.1539 - val_accuracy: 0.9291\n",
            "Epoch 409/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9247\n",
            "Epoch 409: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1780 - accuracy: 0.9247 - val_loss: 0.1584 - val_accuracy: 0.9292\n",
            "Epoch 410/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9267\n",
            "Epoch 410: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1891 - accuracy: 0.9268 - val_loss: 0.1719 - val_accuracy: 0.9332\n",
            "Epoch 411/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9248\n",
            "Epoch 411: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1866 - accuracy: 0.9248 - val_loss: 0.1502 - val_accuracy: 0.9303\n",
            "Epoch 412/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9262\n",
            "Epoch 412: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1756 - accuracy: 0.9262 - val_loss: 0.1479 - val_accuracy: 0.9324\n",
            "Epoch 413/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9242\n",
            "Epoch 413: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2044 - accuracy: 0.9242 - val_loss: 0.1744 - val_accuracy: 0.9278\n",
            "Epoch 414/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9255\n",
            "Epoch 414: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2173 - accuracy: 0.9255 - val_loss: 0.1474 - val_accuracy: 0.9301\n",
            "Epoch 415/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2179 - accuracy: 0.9207\n",
            "Epoch 415: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2177 - accuracy: 0.9207 - val_loss: 0.1620 - val_accuracy: 0.9273\n",
            "Epoch 416/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9233\n",
            "Epoch 416: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1934 - accuracy: 0.9233 - val_loss: 0.1457 - val_accuracy: 0.9293\n",
            "Epoch 417/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9236\n",
            "Epoch 417: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1933 - accuracy: 0.9236 - val_loss: 0.1729 - val_accuracy: 0.9031\n",
            "Epoch 418/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.9231\n",
            "Epoch 418: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2110 - accuracy: 0.9230 - val_loss: 0.1427 - val_accuracy: 0.9317\n",
            "Epoch 419/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.9216\n",
            "Epoch 419: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1885 - accuracy: 0.9216 - val_loss: 0.1941 - val_accuracy: 0.9179\n",
            "Epoch 420/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9227\n",
            "Epoch 420: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1763 - accuracy: 0.9227 - val_loss: 0.1563 - val_accuracy: 0.9298\n",
            "Epoch 421/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9213\n",
            "Epoch 421: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1877 - accuracy: 0.9213 - val_loss: 0.1675 - val_accuracy: 0.9287\n",
            "Epoch 422/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9223\n",
            "Epoch 422: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1870 - accuracy: 0.9223 - val_loss: 0.1427 - val_accuracy: 0.9295\n",
            "Epoch 423/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9210\n",
            "Epoch 423: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2362 - accuracy: 0.9209 - val_loss: 0.1690 - val_accuracy: 0.9270\n",
            "Epoch 424/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9242\n",
            "Epoch 424: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2151 - accuracy: 0.9242 - val_loss: 0.1764 - val_accuracy: 0.9332\n",
            "Epoch 425/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9229\n",
            "Epoch 425: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1994 - accuracy: 0.9230 - val_loss: 0.1454 - val_accuracy: 0.9316\n",
            "Epoch 426/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9208\n",
            "Epoch 426: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2164 - accuracy: 0.9208 - val_loss: 0.1430 - val_accuracy: 0.9307\n",
            "Epoch 427/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9250\n",
            "Epoch 427: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1712 - accuracy: 0.9249 - val_loss: 0.2054 - val_accuracy: 0.9176\n",
            "Epoch 428/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9247\n",
            "Epoch 428: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2078 - accuracy: 0.9247 - val_loss: 0.1864 - val_accuracy: 0.9282\n",
            "Epoch 429/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9186\n",
            "Epoch 429: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2265 - accuracy: 0.9187 - val_loss: 0.1435 - val_accuracy: 0.9298\n",
            "Epoch 430/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1670 - accuracy: 0.9266\n",
            "Epoch 430: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1670 - accuracy: 0.9266 - val_loss: 0.1645 - val_accuracy: 0.9154\n",
            "Epoch 431/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9183\n",
            "Epoch 431: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2636 - accuracy: 0.9181 - val_loss: 0.3052 - val_accuracy: 0.8870\n",
            "Epoch 432/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9210\n",
            "Epoch 432: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1764 - accuracy: 0.9210 - val_loss: 0.1683 - val_accuracy: 0.9298\n",
            "Epoch 433/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9190\n",
            "Epoch 433: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2087 - accuracy: 0.9191 - val_loss: 0.1544 - val_accuracy: 0.9231\n",
            "Epoch 434/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1715 - accuracy: 0.9246\n",
            "Epoch 434: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1714 - accuracy: 0.9246 - val_loss: 0.1440 - val_accuracy: 0.9298\n",
            "Epoch 435/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.9220\n",
            "Epoch 435: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1960 - accuracy: 0.9220 - val_loss: 0.1534 - val_accuracy: 0.9150\n",
            "Epoch 436/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9235\n",
            "Epoch 436: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1971 - accuracy: 0.9235 - val_loss: 0.1896 - val_accuracy: 0.9285\n",
            "Epoch 437/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9233\n",
            "Epoch 437: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2082 - accuracy: 0.9232 - val_loss: 0.1907 - val_accuracy: 0.9263\n",
            "Epoch 438/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9257\n",
            "Epoch 438: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1747 - accuracy: 0.9257 - val_loss: 0.1471 - val_accuracy: 0.9253\n",
            "Epoch 439/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.9143\n",
            "Epoch 439: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2737 - accuracy: 0.9143 - val_loss: 0.2288 - val_accuracy: 0.9248\n",
            "Epoch 440/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9251\n",
            "Epoch 440: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2296 - accuracy: 0.9251 - val_loss: 0.2006 - val_accuracy: 0.9184\n",
            "Epoch 441/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.9243\n",
            "Epoch 441: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2564 - accuracy: 0.9243 - val_loss: 0.1479 - val_accuracy: 0.9269\n",
            "Epoch 442/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9241\n",
            "Epoch 442: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1966 - accuracy: 0.9241 - val_loss: 0.1695 - val_accuracy: 0.9252\n",
            "Epoch 443/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9224\n",
            "Epoch 443: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2320 - accuracy: 0.9224 - val_loss: 0.3680 - val_accuracy: 0.9189\n",
            "Epoch 444/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9120\n",
            "Epoch 444: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2309 - accuracy: 0.9120 - val_loss: 0.1792 - val_accuracy: 0.9161\n",
            "Epoch 445/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9191\n",
            "Epoch 445: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.1534 - val_accuracy: 0.9293\n",
            "Epoch 446/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9250\n",
            "Epoch 446: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1765 - accuracy: 0.9249 - val_loss: 0.1707 - val_accuracy: 0.9267\n",
            "Epoch 447/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9253\n",
            "Epoch 447: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1696 - accuracy: 0.9253 - val_loss: 0.1440 - val_accuracy: 0.9297\n",
            "Epoch 448/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9241\n",
            "Epoch 448: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2024 - accuracy: 0.9241 - val_loss: 0.1427 - val_accuracy: 0.9305\n",
            "Epoch 449/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9257\n",
            "Epoch 449: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1804 - accuracy: 0.9257 - val_loss: 0.1408 - val_accuracy: 0.9313\n",
            "Epoch 450/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9264\n",
            "Epoch 450: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1781 - accuracy: 0.9264 - val_loss: 0.1378 - val_accuracy: 0.9328\n",
            "Epoch 451/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9265\n",
            "Epoch 451: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1600 - accuracy: 0.9265 - val_loss: 0.1662 - val_accuracy: 0.9339\n",
            "Epoch 452/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9220\n",
            "Epoch 452: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2188 - accuracy: 0.9220 - val_loss: 0.1729 - val_accuracy: 0.9306\n",
            "Epoch 453/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9268\n",
            "Epoch 453: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1710 - accuracy: 0.9268 - val_loss: 0.1549 - val_accuracy: 0.9314\n",
            "Epoch 454/500\n",
            "688/688 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9270\n",
            "Epoch 454: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1811 - accuracy: 0.9270 - val_loss: 0.1444 - val_accuracy: 0.9294\n",
            "Epoch 455/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9272\n",
            "Epoch 455: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1704 - accuracy: 0.9272 - val_loss: 0.1681 - val_accuracy: 0.9295\n",
            "Epoch 456/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9260\n",
            "Epoch 456: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2084 - accuracy: 0.9260 - val_loss: 0.1693 - val_accuracy: 0.9240\n",
            "Epoch 457/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9234\n",
            "Epoch 457: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1813 - accuracy: 0.9233 - val_loss: 0.1621 - val_accuracy: 0.9317\n",
            "Epoch 458/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9263\n",
            "Epoch 458: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1799 - accuracy: 0.9263 - val_loss: 0.1544 - val_accuracy: 0.9306\n",
            "Epoch 459/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9216\n",
            "Epoch 459: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2181 - accuracy: 0.9216 - val_loss: 0.1471 - val_accuracy: 0.9289\n",
            "Epoch 460/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9203\n",
            "Epoch 460: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2306 - accuracy: 0.9202 - val_loss: 0.1946 - val_accuracy: 0.9201\n",
            "Epoch 461/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9218\n",
            "Epoch 461: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1817 - accuracy: 0.9218 - val_loss: 0.1600 - val_accuracy: 0.9285\n",
            "Epoch 462/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9219\n",
            "Epoch 462: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1901 - accuracy: 0.9219 - val_loss: 0.1525 - val_accuracy: 0.9259\n",
            "Epoch 463/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9191\n",
            "Epoch 463: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2454 - accuracy: 0.9191 - val_loss: 0.1495 - val_accuracy: 0.9260\n",
            "Epoch 464/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9224\n",
            "Epoch 464: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2062 - accuracy: 0.9224 - val_loss: 0.1617 - val_accuracy: 0.9253\n",
            "Epoch 465/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9235\n",
            "Epoch 465: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1733 - accuracy: 0.9235 - val_loss: 0.1488 - val_accuracy: 0.9225\n",
            "Epoch 466/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9260\n",
            "Epoch 466: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1785 - accuracy: 0.9260 - val_loss: 0.1471 - val_accuracy: 0.9294\n",
            "Epoch 467/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9254\n",
            "Epoch 467: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1727 - accuracy: 0.9254 - val_loss: 0.1475 - val_accuracy: 0.9262\n",
            "Epoch 468/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9225\n",
            "Epoch 468: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2111 - accuracy: 0.9225 - val_loss: 0.1618 - val_accuracy: 0.9260\n",
            "Epoch 469/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9238\n",
            "Epoch 469: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1986 - accuracy: 0.9238 - val_loss: 0.1503 - val_accuracy: 0.9293\n",
            "Epoch 470/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9192\n",
            "Epoch 470: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2100 - accuracy: 0.9192 - val_loss: 0.1527 - val_accuracy: 0.9264\n",
            "Epoch 471/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9243\n",
            "Epoch 471: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1790 - accuracy: 0.9242 - val_loss: 0.1501 - val_accuracy: 0.9266\n",
            "Epoch 472/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9226\n",
            "Epoch 472: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1908 - accuracy: 0.9226 - val_loss: 0.2057 - val_accuracy: 0.9246\n",
            "Epoch 473/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.9189\n",
            "Epoch 473: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1990 - accuracy: 0.9190 - val_loss: 0.1596 - val_accuracy: 0.9218\n",
            "Epoch 474/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1721 - accuracy: 0.9200\n",
            "Epoch 474: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1721 - accuracy: 0.9200 - val_loss: 0.1455 - val_accuracy: 0.9298\n",
            "Epoch 475/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9234\n",
            "Epoch 475: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1799 - accuracy: 0.9234 - val_loss: 0.1551 - val_accuracy: 0.9300\n",
            "Epoch 476/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9210\n",
            "Epoch 476: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1776 - accuracy: 0.9210 - val_loss: 0.2520 - val_accuracy: 0.9268\n",
            "Epoch 477/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9213\n",
            "Epoch 477: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1895 - accuracy: 0.9213 - val_loss: 0.1638 - val_accuracy: 0.9218\n",
            "Epoch 478/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9218\n",
            "Epoch 478: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2176 - accuracy: 0.9218 - val_loss: 0.1547 - val_accuracy: 0.9181\n",
            "Epoch 479/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9182\n",
            "Epoch 479: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2349 - accuracy: 0.9182 - val_loss: 0.3175 - val_accuracy: 0.9090\n",
            "Epoch 480/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9044\n",
            "Epoch 480: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2410 - accuracy: 0.9044 - val_loss: 0.1665 - val_accuracy: 0.9114\n",
            "Epoch 481/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9148\n",
            "Epoch 481: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2718 - accuracy: 0.9148 - val_loss: 0.4162 - val_accuracy: 0.9152\n",
            "Epoch 482/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9155\n",
            "Epoch 482: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2721 - accuracy: 0.9154 - val_loss: 0.2661 - val_accuracy: 0.9086\n",
            "Epoch 483/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.9211\n",
            "Epoch 483: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1992 - accuracy: 0.9211 - val_loss: 0.1900 - val_accuracy: 0.9098\n",
            "Epoch 484/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9179\n",
            "Epoch 484: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2171 - accuracy: 0.9179 - val_loss: 0.1802 - val_accuracy: 0.9244\n",
            "Epoch 485/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2378 - accuracy: 0.9191\n",
            "Epoch 485: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2377 - accuracy: 0.9190 - val_loss: 0.1642 - val_accuracy: 0.9214\n",
            "Epoch 486/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9230\n",
            "Epoch 486: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2056 - accuracy: 0.9230 - val_loss: 0.1513 - val_accuracy: 0.9293\n",
            "Epoch 487/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9234\n",
            "Epoch 487: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1790 - accuracy: 0.9234 - val_loss: 0.1626 - val_accuracy: 0.9274\n",
            "Epoch 488/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9234\n",
            "Epoch 488: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1716 - accuracy: 0.9234 - val_loss: 0.1873 - val_accuracy: 0.9283\n",
            "Epoch 489/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.9256\n",
            "Epoch 489: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1829 - accuracy: 0.9256 - val_loss: 0.1784 - val_accuracy: 0.9287\n",
            "Epoch 490/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9257\n",
            "Epoch 490: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2125 - accuracy: 0.9257 - val_loss: 0.1700 - val_accuracy: 0.9307\n",
            "Epoch 491/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9241\n",
            "Epoch 491: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1838 - accuracy: 0.9241 - val_loss: 0.1749 - val_accuracy: 0.9242\n",
            "Epoch 492/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.9231\n",
            "Epoch 492: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3344 - accuracy: 0.9231 - val_loss: 0.1651 - val_accuracy: 0.9306\n",
            "Epoch 493/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2382 - accuracy: 0.9242\n",
            "Epoch 493: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2379 - accuracy: 0.9242 - val_loss: 0.1507 - val_accuracy: 0.9303\n",
            "Epoch 494/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.9264\n",
            "Epoch 494: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.3217 - accuracy: 0.9264 - val_loss: 0.1501 - val_accuracy: 0.9305\n",
            "Epoch 495/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9219\n",
            "Epoch 495: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1887 - accuracy: 0.9219 - val_loss: 0.1642 - val_accuracy: 0.9238\n",
            "Epoch 496/500\n",
            "686/688 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9233\n",
            "Epoch 496: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2205 - accuracy: 0.9233 - val_loss: 0.1477 - val_accuracy: 0.9301\n",
            "Epoch 497/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1917 - accuracy: 0.9240\n",
            "Epoch 497: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1917 - accuracy: 0.9240 - val_loss: 0.1654 - val_accuracy: 0.9245\n",
            "Epoch 498/500\n",
            "685/688 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9252\n",
            "Epoch 498: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2150 - accuracy: 0.9252 - val_loss: 0.1477 - val_accuracy: 0.9300\n",
            "Epoch 499/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9219\n",
            "Epoch 499: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.2115 - accuracy: 0.9219 - val_loss: 0.1424 - val_accuracy: 0.9333\n",
            "Epoch 500/500\n",
            "687/688 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9234\n",
            "Epoch 500: val_loss did not improve from 0.12873\n",
            "688/688 [==============================] - 13s 19ms/step - loss: 0.1776 - accuracy: 0.9233 - val_loss: 0.1606 - val_accuracy: 0.9233\n",
            "('Training time=', 6471.450477600098)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################### 2\n",
        "from contextlib import redirect_stdout\n",
        "with open('./'+name_file+\".xls\", 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model_lstm.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:51.028021Z",
          "iopub.execute_input": "2022-04-26T14:56:51.028287Z",
          "iopub.status.idle": "2022-04-26T14:56:51.036409Z",
          "shell.execute_reply.started": "2022-04-26T14:56:51.028258Z",
          "shell.execute_reply": "2022-04-26T14:56:51.035281Z"
        },
        "trusted": true,
        "id": "_62cN0RjuIIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "log_data = pd.read_csv('./training.log', sep=',', engine='python')\n",
        "#print (log_data)\n",
        "LSTM =log_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:53.616990Z",
          "iopub.execute_input": "2022-04-26T14:56:53.617267Z",
          "iopub.status.idle": "2022-04-26T14:56:53.625589Z",
          "shell.execute_reply.started": "2022-04-26T14:56:53.617238Z",
          "shell.execute_reply": "2022-04-26T14:56:53.624832Z"
        },
        "trusted": true,
        "id": "m1aQMuRMuIIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (name_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:56.037116Z",
          "iopub.execute_input": "2022-04-26T14:56:56.037377Z",
          "iopub.status.idle": "2022-04-26T14:56:56.042235Z",
          "shell.execute_reply.started": "2022-04-26T14:56:56.037347Z",
          "shell.execute_reply": "2022-04-26T14:56:56.041477Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5EEqg_PuIIu",
        "outputId": "56d1384f-2abf-4903-9273-97b686cc986a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "LSTM11_history_11=np.load('./LSTM_data_2_@history.npy',allow_pickle='TRUE').item()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:58.036876Z",
          "iopub.execute_input": "2022-04-26T14:56:58.037673Z",
          "iopub.status.idle": "2022-04-26T14:56:58.042925Z",
          "shell.execute_reply.started": "2022-04-26T14:56:58.037628Z",
          "shell.execute_reply": "2022-04-26T14:56:58.042228Z"
        },
        "trusted": true,
        "id": "TUYLZnVouIIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "####################### 1\n",
        "name_file11 = './LSTM_dataset_2.h5' \n",
        "fashion_model = load_model(name_file11) # load model\n",
        "fashion_model.summary() # summarize model."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:00.602247Z",
          "iopub.execute_input": "2022-04-26T14:57:00.602486Z",
          "iopub.status.idle": "2022-04-26T14:57:01.260140Z",
          "shell.execute_reply.started": "2022-04-26T14:57:00.602448Z",
          "shell.execute_reply": "2022-04-26T14:57:01.259228Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oL19a4BuIIv",
        "outputId": "a79c1f45-bf0d-42c4-cd27-294b7d395d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 16, 512)           1052672   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 16, 256)           787456    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16, 128)           32896     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16, 64)            8256      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 64)            0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16, 32)            2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16, 32)            0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,884,386\n",
            "Trainable params: 1,884,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy=fashion_model.evaluate(X_test ,Y_test) ## to get test accuracy and losses\n",
        "print(val_loss, val_accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:04.388238Z",
          "iopub.execute_input": "2022-04-26T14:57:04.388522Z",
          "iopub.status.idle": "2022-04-26T14:57:08.311042Z",
          "shell.execute_reply.started": "2022-04-26T14:57:04.388490Z",
          "shell.execute_reply": "2022-04-26T14:57:08.310288Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icapOpdQuIIw",
        "outputId": "8f8879c8-6016-4e9e-acd3-ad98cee5bbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1611/1611 [==============================] - 8s 4ms/step - loss: 0.1287 - accuracy: 0.9381\n",
            "0.12873387336730957 0.9381003379821777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "time2=time.time()\n",
        "predict_prob=fashion_model.predict(X_test)\n",
        "y_pred=np.argmax(predict_prob,axis=1)\n",
        "print ('classification time:', time.time()-time2)\n",
        "\n",
        "##print (y_pred)\n",
        "y_true=np.argmax(Y_test, axis=1)\n",
        "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "CM = confusion_matrix(y_true, y_pred)\n",
        "print (CM)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: tp / (tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        "#-----------  IoU\n",
        "from sklearn.metrics import jaccard_score\n",
        "print ('IoU:', jaccard_score(y_true, y_pred, average='micro'))\n",
        "\n",
        "\n",
        "test_eval = fashion_model.evaluate(X_test, Y_test)\n",
        "\n",
        "loss, accuracy = fashion_model.evaluate(X_train, Y_train)\n",
        "print('loss_train: ', loss, 'accuracy_train: ', accuracy)\n",
        "print('Test loss:', test_eval[0], 'Test accuracy:', test_eval[1])\n",
        "\n",
        "TN = CM[0][0]\n",
        "FN = CM[1][0]\n",
        "TP = CM[1][1]\n",
        "FP = CM[0][1]\n",
        "#================ classification metrics\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "print ('TPR',TPR)   \n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP) \n",
        "print('TNR',TNR)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FN)\n",
        "print ('PPV', PPV)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "print('NPV', NPV)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "print('FPR',FPR)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "print ('FNR',FNR)  \n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "print ('FDR',FDR)    \n",
        "# Overall accuracy   \n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "print ('ACC',ACC)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:10.698418Z",
          "iopub.execute_input": "2022-04-26T14:57:10.698866Z",
          "iopub.status.idle": "2022-04-26T14:57:29.956183Z",
          "shell.execute_reply.started": "2022-04-26T14:57:10.698826Z",
          "shell.execute_reply": "2022-04-26T14:57:29.955500Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz8donUvuIIw",
        "outputId": "55f2c949-6df5-4816-c64e-f31dc3dc2ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification time: 6.171212673187256\n",
            "[[17449  1187]\n",
            " [ 2003 30896]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92     18636\n",
            "           1       0.96      0.94      0.95     32899\n",
            "\n",
            "    accuracy                           0.94     51535\n",
            "   macro avg       0.93      0.94      0.93     51535\n",
            "weighted avg       0.94      0.94      0.94     51535\n",
            "\n",
            "Precision: 0.939145\n",
            "Recall: 0.938100\n",
            "F1 score: 0.938375\n",
            "IoU: 0.8834170854271357\n",
            "1611/1611 [==============================] - 7s 4ms/step - loss: 0.1287 - accuracy: 0.9381\n",
            "6442/6442 [==============================] - 27s 4ms/step - loss: 0.1269 - accuracy: 0.9378\n",
            "loss_train:  0.12693153321743011 accuracy_train:  0.9378135204315186\n",
            "Test loss: 0.12873387336730957 Test accuracy: 0.9381003379821777\n",
            "TPR 0.9391166904769142\n",
            "TNR 0.9363060742648637\n",
            "PPV 0.9391166904769142\n",
            "NPV 0.8970285831791075\n",
            "FPR 0.0636939257351363\n",
            "FNR 0.06088330952308581\n",
            "FDR 0.0369977869899947\n",
            "ACC 0.9381003201707577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = LSTM11_history_11 "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:31.530432Z",
          "iopub.execute_input": "2022-04-26T14:57:31.530995Z",
          "iopub.status.idle": "2022-04-26T14:57:31.535364Z",
          "shell.execute_reply.started": "2022-04-26T14:57:31.530953Z",
          "shell.execute_reply": "2022-04-26T14:57:31.534666Z"
        },
        "trusted": true,
        "id": "6-msydZFuIIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Normal','Attack']\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,normalize=False,title=None, cmap=plt.cm.Reds):\n",
        "                                              \n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = None    ### 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = None        ### 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "#    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    ax.tick_params(labelsize=12)       #7777777777777777777777777777777777777777777777777777\n",
        "    cmap=plt.cm.Reds                      #  cmap=plt.cm.Blues\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    cbar = ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    for t in cbar.ax.get_yticklabels():\n",
        "        t.set_fontsize(15)\n",
        "    \n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "             \n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "font = {'family' : 'Times New Roman',\n",
        "        'color'  : 'black',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 15}\n",
        "\n",
        "np.set_printoptions(precision=2) ########################## 2\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,title= None)             \n",
        "plt.xlabel('Predicted label', fontsize=18)\n",
        "plt.ylabel('True label', fontsize=18)\n",
        "plt.savefig('confusion matrix_1_'+name_file+'.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,title=None)            \n",
        "plt.xlabel('Predicted label', fontsize=18)\n",
        "plt.ylabel('True label', fontsize=18)\n",
        "plt.savefig('confusion matrix_2_'+name_file+'.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:39.914968Z",
          "iopub.execute_input": "2022-04-26T14:57:39.915222Z",
          "iopub.status.idle": "2022-04-26T14:57:40.633062Z",
          "shell.execute_reply.started": "2022-04-26T14:57:39.915193Z",
          "shell.execute_reply": "2022-04-26T14:57:40.632398Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wsI273vNuIIy",
        "outputId": "7b1e74fb-d464-4f12-d6c4-4240e43e56ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized confusion matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#history_dict=cnn11.history\n",
        "loss_values=history_dict['loss']\n",
        "val_loss_values=history_dict['val_loss']\n",
        "acc_values=history_dict['accuracy']\n",
        "val_acc_values=history_dict['val_accuracy']\n",
        "epochs=range(1, len(acc_values)+1)\n",
        "def smooth_curve(points, factor=0.8):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "loss_values=smooth_curve(loss_values)\n",
        "val_loss_values=smooth_curve(val_loss_values)\n",
        "acc_values=smooth_curve(acc_values)\n",
        "val_acc_values=smooth_curve(val_acc_values)\n",
        "\n",
        "font = {'family' : 'serif',\n",
        "        'color'  : 'black',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "        \n",
        "\n",
        "plt.plot(epochs, acc_values, 'ro', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'g', label='Validation acc')\n",
        "plt.title('Training and Validation acc', fontdict=font)\n",
        "plt.xlabel('Epochs', fontdict=font)\n",
        "plt.ylabel('Accuracy', fontdict=font)\n",
        "plt.legend()\n",
        "plt.savefig(\"accuracy\"+name_file+\".png\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss', fontdict=font)\n",
        "plt.xlabel('Epochs',fontdict=font)\n",
        "plt.ylabel('Loss',fontdict=font)\n",
        "plt.legend()\n",
        "plt.savefig(\"loss\"+name_file+\".png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:57:34.793670Z",
          "iopub.execute_input": "2022-04-26T14:57:34.793963Z",
          "iopub.status.idle": "2022-04-26T14:57:35.316115Z",
          "shell.execute_reply.started": "2022-04-26T14:57:34.793930Z",
          "shell.execute_reply": "2022-04-26T14:57:35.315404Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "FE3sMwpHuIIx",
        "outputId": "031b3911-dc92-4e26-f7e9-3ad717d1cba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink(r'./LSTM_dataset_2.h5') #======================="
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-26T14:56:44.919211Z",
          "iopub.status.idle": "2022-04-26T14:56:44.919921Z",
          "shell.execute_reply.started": "2022-04-26T14:56:44.919644Z",
          "shell.execute_reply": "2022-04-26T14:56:44.919670Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xzTzFnGDuIIz",
        "outputId": "60e16eb3-9a17-4ec7-c473-60f0c1bc6756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/LSTM_dataset_2.h5"
            ],
            "text/html": [
              "<a href='./LSTM_dataset_2.h5' target='_blank'>./LSTM_dataset_2.h5</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}